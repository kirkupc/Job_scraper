{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "#import ast\n",
    "from all_functions import *\n",
    "import math\n",
    "import requests\n",
    "from pylatex import Document, Section, Subsection, Command\n",
    "from pylatex.utils import italic, NoEscape\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import subprocess\n",
    "import urllib.request\n",
    "import codecs\n",
    "import unidecode\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address(query, api_key):\n",
    "        base = 'https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input='\n",
    "        locationbias= '42.3314584645106, -71.1039191294055'\n",
    "        #key = api_key\n",
    "        query = query\n",
    "        fields = 'formatted_address,name,geometry'\n",
    "        inputtype = 'textquery'\n",
    "        \n",
    "        url_search = base + query + '&inputtype=' + inputtype + '&fields=' + fields + '&locationbias=circle:2000@' + locationbias + '&key=' + api_key\n",
    "        print(url_search)\n",
    "        my_dict = requests.get(url_search).json()\n",
    "        return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commute(dest, origin, api_key):\n",
    "    \n",
    "    base = 'https://maps.googleapis.com/maps/api/distancematrix/json?units=imperial&'\n",
    "    origin = 'origins=' + origin + '&'\n",
    "    dest_str = 'destinations=' + dest + '&'\n",
    "    api_key = 'key=' + api_key\n",
    "    \n",
    "    url_search = base + origin + dest_str + api_key\n",
    "    print(url_search)\n",
    "    my_dict = requests.get(url_search).json()\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_duration(company_list, id_list, api_key):\n",
    "    comm_df = pd.DataFrame(columns=['company', 'place', 'address', 'distance', 'duration'])\n",
    "    for index, company in enumerate(company_list):\n",
    "        comm_dict = {}\n",
    "        company = company\n",
    "        tmp_id = id_list[int(index)]\n",
    "        text_dict = get_address(str(company), api_key=api_key)\n",
    "        #print(text_dict)\n",
    "        if text_dict['status'] == 'ZERO_RESULTS':\n",
    "            print(company + ' has 0 results in get_address.')\n",
    "            base = 'https://maps.googleapis.com/maps/api/staticmap?'\n",
    "            place = 'None'\n",
    "            address = 'None'\n",
    "            distance = 'None'\n",
    "            duration = 'None'\n",
    "            #params = {'center' : '8 Oswald Street, Boston MA 02120' , 'zoom' : '20', 'size' : '200x200' , 'maptype' : 'roadmap', 'key': api_key}\n",
    "            params = {'center' : '8 Oswald Street, Boston MA 02120' , 'zoom' : '10', 'size' : '200x200' , 'maptype' : 'roadmap', 'key': api_key}\n",
    "            map_url = requests.get(base, params).url\n",
    "        else:\n",
    "            address = text_dict['candidates'][0]['formatted_address']\n",
    "            place = text_dict['candidates'][0]['name']    \n",
    "            res_lat_lng = str(text_dict['candidates'][0]['geometry']['location']['lat']) + ',' + str(text_dict['candidates'][0]['geometry']['location']['lng'])\n",
    "            base = 'https://maps.googleapis.com/maps/api/staticmap?'\n",
    "            #params = {'center' : '8 Oswald Street, Boston MA 02120' , 'zoom' : '18', 'size' : '200x200' , 'maptype' : 'roadmap', 'markers': 'color:blue|label:S|' + res_lat_lng, 'key': api_key} \n",
    "            params = {'center' : '8 Oswald Street, Boston MA 02120' , 'size' : '200x200' , 'maptype' : 'roadmap', 'markers': 'color:blue|label:S|' + res_lat_lng, 'key': api_key} \n",
    "            map_url = requests.get(base, params).url\n",
    "            \n",
    "            \n",
    "            comm = get_commute(dest=res_lat_lng, origin='8 Oswald Street, 02120', api_key=api_key)\n",
    "            if comm['rows'][0]['elements'][0]['status'] == 'ZERO_RESULTS':\n",
    "                print(company + ' has 0 results in get_commute.')\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    distance = (comm['rows'][0]['elements'][0]['distance']['text'])\n",
    "                    duration = (comm['rows'][0]['elements'][0]['duration']['text'])\n",
    "                except:\n",
    "                    #print(comm)\n",
    "                    break\n",
    "\n",
    "        comm_dict['company'] = company\n",
    "        comm_dict['place'] = place\n",
    "        comm_dict['address'] = address\n",
    "        comm_dict['distance'] = distance\n",
    "        comm_dict['duration'] = duration\n",
    "        comm_dict['ID'] = tmp_id\n",
    "        comm_dict['map_url'] = map_url\n",
    "        comm_tmp_df = pd.DataFrame(comm_dict, index = [comm_dict['ID']])\n",
    "        comm_df = comm_df.append(comm_tmp_df, sort=False)\n",
    "    return comm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_scraper(wd, results, job_title, city):\n",
    "    \n",
    "    res_left = results\n",
    "    tot_pg = ((results // 25) + 1)\n",
    "    print('stack total pages: ' + str(tot_pg))\n",
    "    #print('indeed total pages: ' + str(tot_pg))\n",
    "    ID = [str('s-ID-' + str(n)) for n in range(0, results)]\n",
    "    pulldates = [str(time.strftime(\"%m%d%Y\", time.localtime(time.time()))) for n in range(0, results)]\n",
    "    stack_df = pd.DataFrame({'ID' : ID, 'pulldates' : pulldates}).set_index('ID')\n",
    "    for i in range(tot_pg):\n",
    "        url = 'https://stackoverflow.com/jobs?q=python&sort=p&l=boston&d=20&u=Miles&start=' + str(i*25)\n",
    "        pg_IDs = ID[i*25:(i+1)*25]\n",
    "        post_links = [title.get_attribute('href') for title in wd.find_elements_by_xpath(\"//h2[@class='fs-subheading job-details__spaced mb4']//a\")]\n",
    "        #url = 'https://www.indeed.com/jobs?q=python&l=worcester&start=0&sort=date&radius=25'\n",
    "        #print(url)\n",
    "        wd.get(url)\n",
    "        #################### search results ####################     \n",
    "        #comp_locs = [comp_loc.text for comp_loc in wd.find_elements_by_xpath(\"//div[@class='-job-summary']/div[contains(@class, '-company')]\")]\n",
    "        stack_df.loc[pg_IDs, 'comp_locs'] = [comp_loc.text for comp_loc in wd.find_elements_by_xpath(\"//div[@class='-job-summary']/div[contains(@class, '-company')]\")]\n",
    "        test_len = len([comp_loc.text for comp_loc in wd.find_elements_by_xpath(\"//div[@class='-job-summary']/div[contains(@class, '-company')]\")])\n",
    "        \n",
    "        res_len = min(test_len, int(res_left))\n",
    "\n",
    "        #l_companies = [company.text.lower().split(',')[0] for company in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='company']\")]\n",
    "        stack_df.loc[pg_IDs, 'titles'] = [title.text for title in wd.find_elements_by_xpath(\"//h2[@class='fs-subheading job-details__spaced mb4']\")]\n",
    "        stack_df.loc[pg_IDs, 'comp_links'] = ['https://www.stackoverflow.com/jobs/company/' + company.text.replace(' ', '-') for company in wd.find_elements_by_xpath(\"//div[@class='fc-black-700 fs-body2 -company']\")]\n",
    "        stack_df.loc[pg_IDs, 'tags'] = [tag.text for tag in wd.find_elements_by_xpath(\"//div[@class='mt12 -tags']\")]\n",
    "        #stack_df.loc[pg_IDs, 'perks'] = [perk.text for perk in wd.find_elements_by_xpath(\"//div[@class='mt2 -perks']\")]\n",
    "        stack_df.loc[pg_IDs, 'postdates'] = [date.text for date in wd.find_elements_by_xpath(\"//span[contains(@class, 'ps-absolute pt2 r0 fc-black-500 fs-body1 pr12')]\")]\n",
    "        #description = [description.text for description in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='summary']\")]\n",
    "        stack_df.loc[pg_IDs, 'post_links'] = [title.get_attribute('href') for title in wd.find_elements_by_xpath(\"//h2[@class='fs-subheading job-details__spaced mb4']//a\")]\n",
    "\n",
    "        #comp_links = ['https://www.indeed.com/cmp/' + str(company).replace(' ', '-') for company in companies]                    \n",
    "\n",
    "        '''        if res_len < 25:\n",
    "            comp_locs = comp_locs[:res_len]\n",
    "            titles = titles[:res_len]\n",
    "            tags = tags[:res_len]\n",
    "            perks = perks[:res_len]\n",
    "            post_links = post_links[:res_len]\n",
    "            postdates = postdates[:res_len]\n",
    "            comp_links = comp_links[:res_len]'''\n",
    "            \n",
    "            \n",
    "        #ID = [str('s-ID-' + str(n)) for n in range(results-res_left, results-res_left+len(comp_locs))]\n",
    "        #comp_loc = ['' for n in range(results-res_left, results-res_left+len(comp_locs))]\n",
    "        #companies = [company.split(' - ')[0] for company in comp_locs]\n",
    "        #locations = [location.split(' - ')[1] for location in comp_locs]\n",
    "                    \n",
    "        res_left = res_left - res_len\n",
    "\n",
    "        #print(len(titles), len(companies), len(post_links), len(postdates), len(pulldates), len(comp_links))\n",
    "        #return 'bitch'\n",
    "        #stack_df = pd.DataFrame({'ID' : ID, 'title' : titles, 'company' : companies, 'post_link' : post_links, 'comp_link' : comp_links, 'postdate' : postdates, 'pulldate' : pulldates}).set_index('ID') # functional\n",
    "\n",
    "        \n",
    "        #################### post list ####################     \n",
    "        post_list = []\n",
    "        for index, link in enumerate(post_links):\n",
    "            post_id = ID[index]\n",
    "            wd.get(link)\n",
    "            #average_comp_rating = wd.find_element_by_xpath(\"//span[@class='cmp-header-rating-average']\").text\n",
    "            stack_df.loc[post_id, 'body'] = wd.find_element_by_xpath(\"//div[@id='overview-items']\").text\n",
    "            try:\n",
    "                stack_df.loc[post_id, 'benefits'] = wd.find_element_by_xpath(\"//section[@class='-benefits mb32']\").text\n",
    "            except:\n",
    "                stack_df.loc[post_id, 'benefits'] = ''\n",
    "                #print(link)\n",
    "            res_len = res_len - len(post_links)    \n",
    "            \n",
    "            #post_list.append([str(index), body, benefits])\n",
    "        #comp_df = pd.DataFrame(post_list, columns=['ID', 'body_text', 'benefits']).set_index('ID')\n",
    "        #stack_df = stack_df.merge(comp_df)\n",
    "    return stack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_scraper(wd, results, job_title, city, linkedin_username, linkedin_password):\n",
    "    tot_pg = ((results // 25) + 1)\n",
    "    res_left = results\n",
    "    print('linkedin total pages: ' + str(tot_pg))\n",
    "    login_url = 'https://www.linkedin.com/'\n",
    "    wd.get(login_url)\n",
    "    #wd.find_element_by_xpath(\"//a[@class='sign-in-link']\").click\n",
    "    #wd.find_element_by_xpath(\"//a[@class='form-toggle']\").click\n",
    "    login_email = wd.find_element_by_id(\"login-email\")\n",
    "    login_email.send_keys(linkedin_username)\n",
    "    login_pass = wd.find_element_by_id(\"login-password\")\n",
    "    login_pass.send_keys(linkedin_password)\n",
    "    wd.find_element_by_id(\"login-submit\").click\n",
    "    #cookies = wd.get_cookie('bcookie')\n",
    "    \n",
    "    ID = [('L-ID-' + str(n)) for n in range(0, results)]\n",
    "    pulldates = [str(time.strftime(\"%m%d%Y\", time.localtime(time.time()))) for n in range(0, results)]\n",
    "    linkedin_df = pd.DataFrame({'ID' : ID, 'pulldates' : pulldates}).set_index('ID')\n",
    "    for i in range(tot_pg):\n",
    "        url = 'http://www.linkedin.com/jobs/search/?keywords=' + job_title + '&location=' + city + '&sortBy=DD&start=' + str(i*25)\n",
    "        print('Page {} url : {}'.format(i, url))\n",
    "        wd.get(url)\n",
    "        pg_IDs = ID[i*25:(i+1)*25] # Gets 25 IDs relevant to page\n",
    "        res_len = min(len(wd.find_elements_by_xpath(\"//li[@class='job-listing']\")), int(res_left))\n",
    "        companies = [c.text for c in wd.find_elements_by_xpath(\"//span[@class='company-name-text']\")]\n",
    "        locations = [L.text for L in wd.find_elements_by_xpath(\"//span[@class='job-location']/span\")]\n",
    "        comp_links = []\n",
    "        for elem in wd.find_elements_by_xpath(\"//div[@class='company-name']\"):\n",
    "            if elem.find_element_by_xpath(\"//a\") == None:\n",
    "                comp_links.append('NA')\n",
    "            else:\n",
    "                comp_links.append(elem.find_element_by_xpath(\"//a\").get_attribute('href'))\n",
    "        linkedin_df.loc[pg_IDs, 'comp_links'] = comp_links\n",
    "        linkedin_df.loc[pg_IDs, 'post_links'] = [l.get_attribute('href') for l in wd.find_elements_by_xpath(\"//a[@class='job-title-link']\")]\n",
    "        linkedin_df.loc[pg_IDs, 'titles'] = [t.text for t in wd.find_elements_by_xpath(\"//span[@class='job-title-text']\")]\n",
    "        linkedin_df.loc[pg_IDs, 'locations'] = [L.text for L in wd.find_elements_by_xpath(\"//span[@class='job-location']/span\")]\n",
    "        linkedin_df.loc[pg_IDs, 'companies'] = [c.text for c in wd.find_elements_by_xpath(\"//span[@class='company-name-text']\")]\n",
    "        linkedin_df.loc[pg_IDs, 'descr'] = [d.text for d in wd.find_elements_by_xpath(\"//div[@class='job-description']\")]\n",
    "        linkedin_df.loc[pg_IDs, 'ezapply'] = [e.text for e in wd.find_elements_by_xpath(\"//div[@class='job-flavor-in-apply-container']\")]\n",
    "        linkedin_df.loc[pg_IDs, 'company_pics'] = [i.get_attribute('src') for i in wd.find_elements_by_xpath(\"//a[@class='company-logo-link']//img\")]\n",
    "\n",
    "        comp_loc = []\n",
    "        for i, elem in enumerate(companies):\n",
    "            comp_loc_str = (elem.strip().split(',')[1:] + ', ' + locations[i].strip())\n",
    "            comp_loc.append(comp_loc_str)\n",
    "        linkedin_df.loc[pg_IDs, 'comp_loc'] = comp_loc\n",
    "        res_left = res_left - res_len\n",
    "    return linkedin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indeed_scraper(wd, results, job_title, city):\n",
    "    list_o_divs = []\n",
    "    #tot_pg = ((results // 10) + 1)\n",
    "    res_left = results\n",
    "    tot_pg = ((results // 10) + 1)\n",
    "    print('indeed total pages: ' + str(tot_pg))\n",
    "    #print('indeed total pages: ' + str(tot_pg))\n",
    "    ID = [('i-ID-' + str(n)) for n in range(0, results)]\n",
    "    pulldates = [str(time.strftime(\"%m%d%Y\", time.localtime(time.time()))) for n in range(0, results)]\n",
    "    indeed_df = pd.DataFrame({'ID' : ID, 'pulldate' : pulldates}).set_index('ID')\n",
    "    for i in range(tot_pg):\n",
    "        url = 'https://www.indeed.com/jobs?q=' + job_title + '&l=' + city + '&start=' + str(i*10) + '&sort=' + 'date' + '&radius=' + '25'\n",
    "        pg_IDs = ID[i*10:(i+1)*10] # Gets 25 IDs relevant to page\n",
    "        #url = 'https://www.indeed.com/jobs?q=python&l=worcester&start=0&sort=date&radius=25'\n",
    "        print('Page {} url : {}'.format(i, url))\n",
    "        wd.get(url)\n",
    "        #################### search results ####################     \n",
    "        \n",
    "        listing_len = len([job for job in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']\")])\n",
    "        res_len = min(listing_len, int(res_left))\n",
    "        \n",
    "        indeed_df.loc[pg_IDs, 'companies'] = [company.text for company in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='company']\")][:res_len]\n",
    "\n",
    "        #res_len = min(listing_len, int(res_left))\n",
    "\n",
    "        indeed_df.loc[pg_IDs, 'l_companies'] = [company.text.lower().split(',')[0] for company in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='company']\")][:res_len]\n",
    "        indeed_df.loc[pg_IDs, 'titles'] = [title.text for title in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//h2[@class='jobtitle']\")][:res_len]\n",
    "        indeed_df.loc[pg_IDs, 'description'] = [description.text for description in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='summary']\")][:res_len]\n",
    "        indeed_df.loc[pg_IDs, 'post_links'] = [post_link.get_attribute('href') for post_link in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//h2[@class='jobtitle']//a\")][:res_len]\n",
    "        indeed_df.loc[pg_IDs, 'comp_links'] = ['https://www.indeed.com/cmp/' + str(company.text).replace(' ', '-') for company in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='company']\")][:res_len]           \n",
    "        post_links = [post_link.get_attribute('href') for post_link in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//h2[@class='jobtitle']//a\")][:res_len]\n",
    "        comp_links = ['https://www.indeed.com/cmp/' + str(company).replace(' ', '-') for company in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='company']\")][:res_len]\n",
    "        '''if res_len < 25:\n",
    "            l_companies = l_companies[:res_len]\n",
    "            titles = titles[:res_len]\n",
    "            description = description[:res_len]\n",
    "            companies = companies[:res_len]\n",
    "            post_links = post_links[:res_len]\n",
    "            comp_links = comp_links[:res_len]'''\n",
    "\n",
    "        \n",
    "\n",
    "        #list_df = pd.DataFrame({'ID' : ID, 'title' : titles, 'company' : companies, 'summary' : description, 'post_link' : post_links, 'comp_link' : comp_links, 'l_company' : l_companies, 'pulldate' : pulldates}) # functional\n",
    "        #list_df['ID'] = list_df['ID'].astype('str')\n",
    "\n",
    "        #################### comp list ####################     \n",
    "        comp_list = []\n",
    "        for index, link in enumerate(comp_links):\n",
    "            index = ID[index]\n",
    "            wd.get(link)\n",
    "            try:\n",
    "                indeed_df.loc[index, 'company_name'] = wd.find_element_by_xpath(\"//div[@class='cmp-company-name-container']\").text\n",
    "                indeed_df.loc[index, 'l_company_name'] = wd.find_element_by_xpath(\"//div[@class='cmp-company-name-container']\").text.lower().split(',')[0]\n",
    "                indeed_df.loc[index, 'salaries_link'] = 'https://www.indeed.com/cmp/' + wd.find_element_by_xpath(\"//div[@class='cmp-company-name-container']\").text + '/salaries/'\n",
    "                indeed_df.loc[index, 'reviews_link'] = 'https://www.indeed.com/cmp/' + wd.find_element_by_xpath(\"//div[@class='cmp-company-name-container']\").text + '/reviews/'\n",
    "                try:\n",
    "                    indeed_df.loc[index, 'average_comp_rating'] = wd.find_element_by_xpath(\"//span[@class='cmp-header-rating-average']\").text\n",
    "                except:\n",
    "                    indeed_df.loc[index, 'average_comp_rating'] = 'Not ranked.'\n",
    "            except:\n",
    "                indeed_df.loc[index, 'company_name'] = ''\n",
    "                indeed_df.loc[index, 'l_company_name'] = ''\n",
    "                indeed_df.loc[index, 'salaries_link'] = ''\n",
    "                indeed_df.loc[index, 'reviews_link'] = ''\n",
    "                continue\n",
    "            \n",
    "            #comp_list.append([str(index), company_name, average_comp_rating, salaries_link, reviews_link, l_company_name])\n",
    "        #comp_df = pd.DataFrame(comp_list, columns=['ID', 'company', 'rating', 'salaries_link', 'reviews_link', 'l_company'])\n",
    "\n",
    "        #################### Post list ####################     \n",
    "        post_list = []\n",
    "        for index, link in enumerate(post_links):\n",
    "            index = ID[index]\n",
    "            wd.get(link)\n",
    "            indeed_df.loc[index, 'jobtitle'] = wd.find_element_by_xpath(\"//h3[contains(@class, 'jobsearch-JobInfoHeader-title')]\").text\n",
    "            try:\n",
    "                indeed_df.loc[index, 'company_pic'] = wd.find_element_by_xpath(\"//img[@class='jobsearch-CompanyAvatar-image']\").get_attribute('src')\n",
    "            except:\n",
    "                indeed_df.loc[index, 'company_pic'] = 'NA'\n",
    "            line = wd.find_element_by_xpath(\"//div[contains(@class, 'jobsearch-InlineCompanyRating')]\").text\n",
    "            indeed_df.loc[index, 'location'] = line.split('\\n')[-1]\n",
    "            indeed_df.loc[index, 'company_name'] = line.split('\\n')[0]\n",
    "            indeed_df.loc[index, 'l_company_name'] = line.split('\\n')[0].lower().split(',')[0]\n",
    "            indeed_df.loc[index, 'comp_loc'] = line.split('\\n')[0] + ', ' + line.split('\\n')[-1]\n",
    "            indeed_df.loc[index, 'body'] = wd.find_element_by_xpath(\"//div[contains(@class, 'jobsearch-JobComponent-description')]\").text\n",
    "            indeed_df.loc[index, 'post_time'] = wd.find_element_by_xpath(\"//div[@class='jobsearch-JobMetadataFooter']\").text.split(' - ')[1].strip()\n",
    "            \n",
    "\n",
    "        #post_df = pd.DataFrame(post_list, columns=['ID', 'title', 'company', 'comp_loc', 'postdate', 'location', 'company_pic', 'body_text', 'l_company'])\n",
    "\n",
    "        #################### DF merging ####################                    \n",
    "        #post_comp_df = comp_df.merge(post_df, on=['ID'], how='right').drop(columns=['l_company_y', 'company_y']).rename({'company_x' : 'company', 'l_company_x' : 'l_company'}, axis='columns')\n",
    "        #post_comp_df['ID'] = post_comp_df['ID'].astype('str')\n",
    "        #tmp_df = post_comp_df.merge(list_df, on=['ID'], how='outer').drop(columns=['l_company_y', 'company_y', 'title_y']).rename({'company_x' : 'company', 'l_company_x' : 'l_company', 'title_x' : 'title'}, axis='columns')\n",
    "        #indeed_df = indeed_df.append(tmp_df, sort=False)\n",
    "\n",
    "        #num += len(tmp_df)\n",
    "        res_left = res_left - res_len\n",
    "    return indeed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ult_scrap(**scrap_params):\n",
    "    results = scrap_params['results_per_site']\n",
    "    job_title = scrap_params['job_title']\n",
    "    city = scrap_params['city'] \n",
    "    site_list = scrap_params['site_list']\n",
    "    linkedin_username = scrap_params['linked_in_username'] \n",
    "    linkedin_password = scrap_params['linked_in_password']\n",
    "    chromedriver_location = scrap_params['chromedriver_location'] \n",
    "    api_key = scrap_params['api_key'] \n",
    "    \n",
    "    file = 1\n",
    "    SKIPPER = 0 # Skips this many of the first jobs\n",
    "    #job_col_list = ['site', 'sID',  'title', 'company', 'location', 'salary', 'summary', 'tags','id', 'comp_loc', 'link', 'pulldate','postdate', 'ezapply']\n",
    "    #job_df = pd.DataFrame(columns=job_col_list).set_index('sID')\n",
    "    #indeed_df = pd.DataFrame()\n",
    "    #linkedin_df = pd.DataFrame()\n",
    "    #stack_df = pd.DataFrame()\n",
    "\n",
    "    num = 0\n",
    "    options = Options()\n",
    "    for arg in ['--headless', '--no-sandbox', '--disable-gpu', 'start-maximized', 'disable-infobars', '--disable-extensions']:\n",
    "        options.add_argument(arg)\n",
    "    '''options.add_argument(\"--headless\") # Runs Chrome in headless mode.\n",
    "    options.add_argument('--no-sandbox') # Bypass OS security model\n",
    "    options.add_argument('--disable-gpu')  # applicable to windows os only\n",
    "    options.add_argument('start-maximized') # \n",
    "    options.add_argument('disable-infobars')\n",
    "    options.add_argument(\"--disable-extensions\")'''\n",
    "    wd = webdriver.Chrome(chromedriver_location, options=options)\n",
    "    job_df = pd.DataFrame()\n",
    "    for site in site_list: \n",
    "        site_ind = results\n",
    "        if site == 'stack':\n",
    "            stack_df = stack_scraper(wd, results, job_title, city)\n",
    "            job_df = job_df.append(stack_df, sort=False)\n",
    "            \n",
    "        if site == 'indeed':\n",
    "            indeed_df = indeed_scraper(wd, results, job_title, city)\n",
    "            job_df = job_df.append(indeed_df, sort=False)\n",
    "                    \n",
    "        if site == 'linkedin':\n",
    "            linkedin_df = linkedin_scraper(wd, results, job_title, city, linkedin_username, linkedin_password)\n",
    "            job_df = job_df.append(linkedin_df, sort=False)\n",
    "    return job_df\n",
    "    #job_df = linkedin_df.append(indeed_df, sort=False)\n",
    "    #job_df = job_df.append(stack_df, sort=False)\n",
    "    try:\n",
    "        job_df.set_index('ID', inplace=True)\n",
    "    except:\n",
    "        print('fail')\n",
    "        return indeed_df\n",
    "    companies = job_df['comp_loc']\n",
    "    ids = job_df.index.tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    comm_df = dist_duration(companies, ids, api_key)\n",
    "\n",
    "    fin_df = job_df.merge(comm_df, how = 'left', left_index=True, right_on=['ID']).drop(columns=['company_x']).rename({'company_y' : 'company'}, axis='columns')\n",
    "\n",
    "    file = file + 1\n",
    "    wd.stop_client()\n",
    "    wd.quit()\n",
    "    output_dict = {'job_title' : job_title, 'city' : city}\n",
    "    return fin_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indeed total pages: 3\n",
      "Page 0 url : https://www.indeed.com/jobs?q=python&l=boston&start=0&sort=date&radius=25\n",
      "Page 1 url : https://www.indeed.com/jobs?q=python&l=boston&start=10&sort=date&radius=25\n",
      "Page 2 url : https://www.indeed.com/jobs?q=python&l=boston&start=20&sort=date&radius=25\n",
      "linkedin total pages: 2\n",
      "Page 0 url : http://www.linkedin.com/jobs/search/?keywords=python&location=boston&sortBy=DD&start=0\n",
      "Page 1 url : http://www.linkedin.com/jobs/search/?keywords=python&location=boston&sortBy=DD&start=25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pulldate</th>\n",
       "      <th>companies</th>\n",
       "      <th>l_companies</th>\n",
       "      <th>titles</th>\n",
       "      <th>description</th>\n",
       "      <th>post_links</th>\n",
       "      <th>comp_links</th>\n",
       "      <th>company_name</th>\n",
       "      <th>l_company_name</th>\n",
       "      <th>salaries_link</th>\n",
       "      <th>...</th>\n",
       "      <th>company_pic</th>\n",
       "      <th>location</th>\n",
       "      <th>comp_loc</th>\n",
       "      <th>body</th>\n",
       "      <th>post_time</th>\n",
       "      <th>pulldates</th>\n",
       "      <th>locations</th>\n",
       "      <th>descr</th>\n",
       "      <th>ezapply</th>\n",
       "      <th>company_pics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>i-ID-0</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Ace Technologies</td>\n",
       "      <td>ace technologies</td>\n",
       "      <td>QA Analyst</td>\n",
       "      <td>This person will be doing automation testing o...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=827870af9af1e...</td>\n",
       "      <td>https://www.indeed.com/cmp/Ace-Technologies</td>\n",
       "      <td>IBM</td>\n",
       "      <td>ibm</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Cambridge, MA 02139</td>\n",
       "      <td>IBM, Cambridge, MA 02139</td>\n",
       "      <td>Job Description\\nIBM Research is the innovatio...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-1</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Canonical</td>\n",
       "      <td>canonical</td>\n",
       "      <td>Boston DCE</td>\n",
       "      <td>Python scripting experience. Data Center Engin...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=993a87e42e52d...</td>\n",
       "      <td>https://www.indeed.com/cmp/Canonical</td>\n",
       "      <td>Klaviyo</td>\n",
       "      <td>klaviyo</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Klaviyo, Boston, MA</td>\n",
       "      <td>We love programming and the excitement that co...</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-2</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Wavsys</td>\n",
       "      <td>wavsys</td>\n",
       "      <td>Roboticist</td>\n",
       "      <td>Deep theoretical foundation in relevant artifi...</td>\n",
       "      <td>https://www.indeed.com/company/Wavsys/jobs/Rob...</td>\n",
       "      <td>https://www.indeed.com/cmp/Wavsys</td>\n",
       "      <td>IBM</td>\n",
       "      <td>ibm</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Littleton, MA 01460</td>\n",
       "      <td>IBM, Littleton, MA 01460</td>\n",
       "      <td>Job Description\\nJob Description\\nResponsibili...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-3</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Circulation, Inc.</td>\n",
       "      <td>circulation</td>\n",
       "      <td>Technical Support Engineer</td>\n",
       "      <td>With HTML/CSS, Javascript, Python, Web APIs, a...</td>\n",
       "      <td>https://www.indeed.com/company/Circulation,-In...</td>\n",
       "      <td>https://www.indeed.com/cmp/Circulation,-Inc.</td>\n",
       "      <td>Dassault Systèmes</td>\n",
       "      <td>dassault systèmes</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_squar...</td>\n",
       "      <td>Waltham, MA</td>\n",
       "      <td>Dassault Systèmes, Waltham, MA</td>\n",
       "      <td>Exa part of the family of Simulia products, ba...</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-4</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Agios Pharmaceuticals</td>\n",
       "      <td>agios pharmaceuticals</td>\n",
       "      <td>Bioinformaticist</td>\n",
       "      <td>Strong hands-on programing skills, especially ...</td>\n",
       "      <td>https://www.indeed.com/company/Agios-Pharmaceu...</td>\n",
       "      <td>https://www.indeed.com/cmp/Agios-Pharmaceuticals</td>\n",
       "      <td>Continental Resources</td>\n",
       "      <td>continental resources</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Bedford, MA 01730</td>\n",
       "      <td>Continental Resources, Bedford, MA 01730</td>\n",
       "      <td>Outperform your competition; consider becoming...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-5</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Index Data</td>\n",
       "      <td>index data</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Intermediate knowledge of higher-level languag...</td>\n",
       "      <td>https://www.indeed.com/company/Index-Data/jobs...</td>\n",
       "      <td>https://www.indeed.com/cmp/Index-Data</td>\n",
       "      <td>IBM</td>\n",
       "      <td>ibm</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>https://d2q79iu7y748jz.cloudfront.net/s/_logo/...</td>\n",
       "      <td>Littleton, MA 01460</td>\n",
       "      <td>IBM, Littleton, MA 01460</td>\n",
       "      <td>Job Description\\nAre you interested in pursuin...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-6</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Ace Technologies</td>\n",
       "      <td>ace technologies</td>\n",
       "      <td>Hadoop</td>\n",
       "      <td>Familiar with Hadoop tools/languages such as P...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=4cc6688f09b1e...</td>\n",
       "      <td>https://www.indeed.com/cmp/Ace-Technologies</td>\n",
       "      <td>Onduo</td>\n",
       "      <td>onduo</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Newton, MA 02458</td>\n",
       "      <td>Onduo, Newton, MA 02458</td>\n",
       "      <td>Responsibilities and Duties:\\nOnduo is looking...</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-7</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Positionskart</td>\n",
       "      <td>positionskart</td>\n",
       "      <td>Senior Business Analyst</td>\n",
       "      <td>Development – Python, Powershell, Chef, VRO/VR...</td>\n",
       "      <td>https://www.indeed.com/company/Positionskart/j...</td>\n",
       "      <td>https://www.indeed.com/cmp/Positionskart</td>\n",
       "      <td>Klaviyo</td>\n",
       "      <td>klaviyo</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Klaviyo, Boston, MA</td>\n",
       "      <td>We love programming and the excitement that co...</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-8</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Foundation Medicine, Inc.</td>\n",
       "      <td>foundation medicine</td>\n",
       "      <td>Data Scientist, Clinicogenomics</td>\n",
       "      <td>Proficiency with statistical analysis software...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=7b542a241ad69...</td>\n",
       "      <td>https://www.indeed.com/cmp/Foundation-Medicine...</td>\n",
       "      <td>enEvolv</td>\n",
       "      <td>enevolv</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Medford, MA 02155</td>\n",
       "      <td>enEvolv, Medford, MA 02155</td>\n",
       "      <td>We are seeking a Microfluidics Engineer to joi...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-9</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Aetna</td>\n",
       "      <td>aetna</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Java, Object-Oriented Languages, Python, Spark...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6c8c08a72f7ce...</td>\n",
       "      <td>https://www.indeed.com/cmp/Aetna</td>\n",
       "      <td>enEvolv</td>\n",
       "      <td>enevolv</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>Medford, MA 02155</td>\n",
       "      <td>enEvolv, Medford, MA 02155</td>\n",
       "      <td>The Bioinformatician will be a member of the C...</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-10</th>\n",
       "      <td>11162018</td>\n",
       "      <td>State Street</td>\n",
       "      <td>state street</td>\n",
       "      <td>Global Credit Finance Reporting Manager, AVP</td>\n",
       "      <td>SQL, Python or other coding experience helpful...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=9634b7da90383...</td>\n",
       "      <td>https://www.indeed.com/cmp/State-Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-11</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Liberty Mutual</td>\n",
       "      <td>liberty mutual</td>\n",
       "      <td>Senior Data Scientist, Product Design &amp; Modeli...</td>\n",
       "      <td>Develops programs to analyze large datasets in...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=99c48fcee0769...</td>\n",
       "      <td>https://www.indeed.com/cmp/Liberty-Mutual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-12</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Mitre Corporation</td>\n",
       "      <td>mitre corporation</td>\n",
       "      <td>Software Development Group Lead</td>\n",
       "      <td>Node.js, Vue.js, AngularJS, Python, Java, Elas...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=87ebf0ef7b028...</td>\n",
       "      <td>https://www.indeed.com/cmp/Mitre-Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-13</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Mercury Systems</td>\n",
       "      <td>mercury systems</td>\n",
       "      <td>Principal BIOS Engineer</td>\n",
       "      <td>Experience with any of Python, PERL, or other ...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=47dd47292787d...</td>\n",
       "      <td>https://www.indeed.com/cmp/Mercury-Systems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-14</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Tasacom Technologies</td>\n",
       "      <td>tasacom technologies</td>\n",
       "      <td>Senior QA Engineer</td>\n",
       "      <td>Or native development (C-sharp, Python, Java, ...</td>\n",
       "      <td>https://www.indeed.com/company/Tasacom-Technol...</td>\n",
       "      <td>https://www.indeed.com/cmp/Tasacom-Technologies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-15</th>\n",
       "      <td>11162018</td>\n",
       "      <td>IBM</td>\n",
       "      <td>ibm</td>\n",
       "      <td>Software Engineer Apprentice</td>\n",
       "      <td>Java, JavaScript, PHP, C#, Objective-C, C/C++,...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e64fcde704343...</td>\n",
       "      <td>https://www.indeed.com/cmp/IBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-16</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Onduo</td>\n",
       "      <td>onduo</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Candidates should be complete wizards in BigQu...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6ad0a641211f3...</td>\n",
       "      <td>https://www.indeed.com/cmp/Onduo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-17</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Klaviyo</td>\n",
       "      <td>klaviyo</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>We love programming and the excitement that co...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=42045984aea51...</td>\n",
       "      <td>https://www.indeed.com/cmp/Klaviyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-18</th>\n",
       "      <td>11162018</td>\n",
       "      <td>enEvolv</td>\n",
       "      <td>enevolv</td>\n",
       "      <td>Microfluidics Engineer</td>\n",
       "      <td>We are seeking a Microfluidics Engineer to joi...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=eab111043ccbb...</td>\n",
       "      <td>https://www.indeed.com/cmp/enEvolv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-19</th>\n",
       "      <td>11162018</td>\n",
       "      <td>enEvolv</td>\n",
       "      <td>enevolv</td>\n",
       "      <td>Bioinformatician</td>\n",
       "      <td>Proficiency in programming, scripting, queryin...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0f73c98449959...</td>\n",
       "      <td>https://www.indeed.com/cmp/enEvolv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-20</th>\n",
       "      <td>11162018</td>\n",
       "      <td>IBM</td>\n",
       "      <td>ibm</td>\n",
       "      <td>Research Staff Member, Artificial Intelligence</td>\n",
       "      <td>Python, Java, C++, Matlab, R etc. IBM Research...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=1d04bbf47d9ad...</td>\n",
       "      <td>https://www.indeed.com/cmp/IBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-21</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Klaviyo</td>\n",
       "      <td>klaviyo</td>\n",
       "      <td>Data Science Software Engineer</td>\n",
       "      <td>We love programming and the excitement that co...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=8d2ee06ec67ab...</td>\n",
       "      <td>https://www.indeed.com/cmp/Klaviyo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-22</th>\n",
       "      <td>11162018</td>\n",
       "      <td>IBM</td>\n",
       "      <td>ibm</td>\n",
       "      <td>Advisory Automation Engineer</td>\n",
       "      <td>Proficient with Python, Selenium and other scr...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e99cbc68d7608...</td>\n",
       "      <td>https://www.indeed.com/cmp/IBM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-23</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Dassault Systèmes</td>\n",
       "      <td>dassault systèmes</td>\n",
       "      <td>Aerodynamics Application Engineer - Burlington...</td>\n",
       "      <td>UNIX skills, script programming and knowledge ...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fae74195ddd91...</td>\n",
       "      <td>https://www.indeed.com/cmp/Dassault-Systèmes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i-ID-24</th>\n",
       "      <td>11162018</td>\n",
       "      <td>Continental Resources</td>\n",
       "      <td>continental resources</td>\n",
       "      <td>Microsoft Azure Cloud Engineer</td>\n",
       "      <td>A working understanding of code and script (PH...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=8df3f9fa51fcb...</td>\n",
       "      <td>https://www.indeed.com/cmp/Continental-Resources</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Telepathy Labs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Natural Language Understanding Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-natu...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telepathy Labs, Boston, Massachusetts, United ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Boston, Massachusetts, United States</td>\n",
       "      <td>We are seeking a dynamic, passionate and exper...</td>\n",
       "      <td></td>\n",
       "      <td>https://media.licdn.com/dms/image/C4E0BAQFChPp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MKS Instruments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software/Firmware Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-fi...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MKS Instruments, 90 Industrial Way, Wilmington...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>90 Industrial Way, Wilmington, Massachusetts 0...</td>\n",
       "      <td>MKS Instruments, a worldwide leader in providi...</td>\n",
       "      <td></td>\n",
       "      <td>https://media.licdn.com/dms/image/C4D0BAQGUMM1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>InterSystems</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Product Manager - Machine Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/product-man...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>InterSystems, Cambridge, Massachusetts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Cambridge, Massachusetts</td>\n",
       "      <td>It includes hands-on data science technical wo...</td>\n",
       "      <td></td>\n",
       "      <td>https://media.licdn.com/dms/image/C4E0BAQFhEni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Bruins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Analyst, Hockey Operations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/analyst-hoc...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston Bruins, Boston, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Boston, MA, US</td>\n",
       "      <td>Problem-solving skills – must be able to asses...</td>\n",
       "      <td></td>\n",
       "      <td>https://media.licdn.com/dms/image/C560BAQH8H4U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert Half Technology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full Stack Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/full-stack-...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert Half Technology, Cambridge, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Cambridge, MA, US</td>\n",
       "      <td>Robert Half Technology is searching for a cand...</td>\n",
       "      <td></td>\n",
       "      <td>https://media.licdn.com/dms/image/C4D0BAQEXLtt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-Stack Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/full-stack-...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Acton, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Acton, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Ashland, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Ashland, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHP Developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/php-develop...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Wenham, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Wenham, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-Stack Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/full-stack-...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Humarock, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Humarock, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Easton, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Easton, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-softwa...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Nonantum, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Nonantum, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-Stack Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/full-stack-...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Weymouth, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Weymouth, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-softwa...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, East Walpole, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>East Walpole, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, North Andover, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>North Andover, MA, US</td>\n",
       "      <td>Would you like to build apps for a range of iO...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-softwa...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Norfolk, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Norfolk, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-softwa...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Sherborn, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Sherborn, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-softwa...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Newton, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Newton, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/devops-engi...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Boston, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Boston, MA, US</td>\n",
       "      <td>Responsibilities Working in an agile developme...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Greenbush, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Greenbush, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-softwa...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Avon, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Avon, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lead Developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-develo...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Babson Park, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Babson Park, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-Stack Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/full-stack-...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, North Pembroke, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>North Pembroke, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PHP Developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/php-develop...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Essex, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Essex, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Build/ Release Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/build-relea...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Newton Upper Falls, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Newton Upper Falls, MA, US</td>\n",
       "      <td>Are you interested in building flexibility and...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L-ID-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>https://www.linkedin.com/jobs?trk=jobs_chrome_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hired, Salem, MA, US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11162018</td>\n",
       "      <td>Salem, MA, US</td>\n",
       "      <td>You will also develop and maintain web applica...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pulldate                  companies            l_companies  \\\n",
       "ID                                                                    \n",
       "i-ID-0   11162018           Ace Technologies       ace technologies   \n",
       "i-ID-1   11162018                  Canonical              canonical   \n",
       "i-ID-2   11162018                     Wavsys                 wavsys   \n",
       "i-ID-3   11162018          Circulation, Inc.            circulation   \n",
       "i-ID-4   11162018      Agios Pharmaceuticals  agios pharmaceuticals   \n",
       "i-ID-5   11162018                 Index Data             index data   \n",
       "i-ID-6   11162018           Ace Technologies       ace technologies   \n",
       "i-ID-7   11162018              Positionskart          positionskart   \n",
       "i-ID-8   11162018  Foundation Medicine, Inc.    foundation medicine   \n",
       "i-ID-9   11162018                      Aetna                  aetna   \n",
       "i-ID-10  11162018               State Street           state street   \n",
       "i-ID-11  11162018             Liberty Mutual         liberty mutual   \n",
       "i-ID-12  11162018          Mitre Corporation      mitre corporation   \n",
       "i-ID-13  11162018            Mercury Systems        mercury systems   \n",
       "i-ID-14  11162018       Tasacom Technologies   tasacom technologies   \n",
       "i-ID-15  11162018                        IBM                    ibm   \n",
       "i-ID-16  11162018                      Onduo                  onduo   \n",
       "i-ID-17  11162018                    Klaviyo                klaviyo   \n",
       "i-ID-18  11162018                    enEvolv                enevolv   \n",
       "i-ID-19  11162018                    enEvolv                enevolv   \n",
       "i-ID-20  11162018                        IBM                    ibm   \n",
       "i-ID-21  11162018                    Klaviyo                klaviyo   \n",
       "i-ID-22  11162018                        IBM                    ibm   \n",
       "i-ID-23  11162018          Dassault Systèmes      dassault systèmes   \n",
       "i-ID-24  11162018      Continental Resources  continental resources   \n",
       "L-ID-0        NaN             Telepathy Labs                    NaN   \n",
       "L-ID-1        NaN            MKS Instruments                    NaN   \n",
       "L-ID-2        NaN               InterSystems                    NaN   \n",
       "L-ID-3        NaN              Boston Bruins                    NaN   \n",
       "L-ID-4        NaN     Robert Half Technology                    NaN   \n",
       "L-ID-5        NaN                      Hired                    NaN   \n",
       "L-ID-6        NaN                      Hired                    NaN   \n",
       "L-ID-7        NaN                      Hired                    NaN   \n",
       "L-ID-8        NaN                      Hired                    NaN   \n",
       "L-ID-9        NaN                      Hired                    NaN   \n",
       "L-ID-10       NaN                      Hired                    NaN   \n",
       "L-ID-11       NaN                      Hired                    NaN   \n",
       "L-ID-12       NaN                      Hired                    NaN   \n",
       "L-ID-13       NaN                      Hired                    NaN   \n",
       "L-ID-14       NaN                      Hired                    NaN   \n",
       "L-ID-15       NaN                      Hired                    NaN   \n",
       "L-ID-16       NaN                      Hired                    NaN   \n",
       "L-ID-17       NaN                      Hired                    NaN   \n",
       "L-ID-18       NaN                      Hired                    NaN   \n",
       "L-ID-19       NaN                      Hired                    NaN   \n",
       "L-ID-20       NaN                      Hired                    NaN   \n",
       "L-ID-21       NaN                      Hired                    NaN   \n",
       "L-ID-22       NaN                      Hired                    NaN   \n",
       "L-ID-23       NaN                      Hired                    NaN   \n",
       "L-ID-24       NaN                      Hired                    NaN   \n",
       "\n",
       "                                                    titles  \\\n",
       "ID                                                           \n",
       "i-ID-0                                          QA Analyst   \n",
       "i-ID-1                                          Boston DCE   \n",
       "i-ID-2                                          Roboticist   \n",
       "i-ID-3                          Technical Support Engineer   \n",
       "i-ID-4                                    Bioinformaticist   \n",
       "i-ID-5                                     DevOps Engineer   \n",
       "i-ID-6                                              Hadoop   \n",
       "i-ID-7                             Senior Business Analyst   \n",
       "i-ID-8                     Data Scientist, Clinicogenomics   \n",
       "i-ID-9                                       Data Engineer   \n",
       "i-ID-10       Global Credit Finance Reporting Manager, AVP   \n",
       "i-ID-11  Senior Data Scientist, Product Design & Modeli...   \n",
       "i-ID-12                    Software Development Group Lead   \n",
       "i-ID-13                            Principal BIOS Engineer   \n",
       "i-ID-14                                 Senior QA Engineer   \n",
       "i-ID-15                       Software Engineer Apprentice   \n",
       "i-ID-16                                       Data Analyst   \n",
       "i-ID-17                          Machine Learning Engineer   \n",
       "i-ID-18                             Microfluidics Engineer   \n",
       "i-ID-19                                   Bioinformatician   \n",
       "i-ID-20     Research Staff Member, Artificial Intelligence   \n",
       "i-ID-21                     Data Science Software Engineer   \n",
       "i-ID-22                       Advisory Automation Engineer   \n",
       "i-ID-23  Aerodynamics Application Engineer - Burlington...   \n",
       "i-ID-24                     Microsoft Azure Cloud Engineer   \n",
       "L-ID-0     Senior Natural Language Understanding Scientist   \n",
       "L-ID-1                          Software/Firmware Engineer   \n",
       "L-ID-2                  Product Manager - Machine Learning   \n",
       "L-ID-3                          Analyst, Hockey Operations   \n",
       "L-ID-4                                 Full Stack Engineer   \n",
       "L-ID-5                        Full-Stack Software Engineer   \n",
       "L-ID-6                                   Software Engineer   \n",
       "L-ID-7                                       PHP Developer   \n",
       "L-ID-8                        Full-Stack Software Engineer   \n",
       "L-ID-9                                   Software Engineer   \n",
       "L-ID-10                             Lead Software Engineer   \n",
       "L-ID-11                       Full-Stack Software Engineer   \n",
       "L-ID-12                             Lead Software Engineer   \n",
       "L-ID-13                                  Software Engineer   \n",
       "L-ID-14                             Lead Software Engineer   \n",
       "L-ID-15                             Lead Software Engineer   \n",
       "L-ID-16                             Lead Software Engineer   \n",
       "L-ID-17                                    DevOps Engineer   \n",
       "L-ID-18                                  Software Engineer   \n",
       "L-ID-19                             Lead Software Engineer   \n",
       "L-ID-20                                     Lead Developer   \n",
       "L-ID-21                       Full-Stack Software Engineer   \n",
       "L-ID-22                                      PHP Developer   \n",
       "L-ID-23                            Build/ Release Engineer   \n",
       "L-ID-24                                  Software Engineer   \n",
       "\n",
       "                                               description  \\\n",
       "ID                                                           \n",
       "i-ID-0   This person will be doing automation testing o...   \n",
       "i-ID-1   Python scripting experience. Data Center Engin...   \n",
       "i-ID-2   Deep theoretical foundation in relevant artifi...   \n",
       "i-ID-3   With HTML/CSS, Javascript, Python, Web APIs, a...   \n",
       "i-ID-4   Strong hands-on programing skills, especially ...   \n",
       "i-ID-5   Intermediate knowledge of higher-level languag...   \n",
       "i-ID-6   Familiar with Hadoop tools/languages such as P...   \n",
       "i-ID-7   Development – Python, Powershell, Chef, VRO/VR...   \n",
       "i-ID-8   Proficiency with statistical analysis software...   \n",
       "i-ID-9   Java, Object-Oriented Languages, Python, Spark...   \n",
       "i-ID-10  SQL, Python or other coding experience helpful...   \n",
       "i-ID-11  Develops programs to analyze large datasets in...   \n",
       "i-ID-12  Node.js, Vue.js, AngularJS, Python, Java, Elas...   \n",
       "i-ID-13  Experience with any of Python, PERL, or other ...   \n",
       "i-ID-14  Or native development (C-sharp, Python, Java, ...   \n",
       "i-ID-15  Java, JavaScript, PHP, C#, Objective-C, C/C++,...   \n",
       "i-ID-16  Candidates should be complete wizards in BigQu...   \n",
       "i-ID-17  We love programming and the excitement that co...   \n",
       "i-ID-18  We are seeking a Microfluidics Engineer to joi...   \n",
       "i-ID-19  Proficiency in programming, scripting, queryin...   \n",
       "i-ID-20  Python, Java, C++, Matlab, R etc. IBM Research...   \n",
       "i-ID-21  We love programming and the excitement that co...   \n",
       "i-ID-22  Proficient with Python, Selenium and other scr...   \n",
       "i-ID-23  UNIX skills, script programming and knowledge ...   \n",
       "i-ID-24  A working understanding of code and script (PH...   \n",
       "L-ID-0                                                 NaN   \n",
       "L-ID-1                                                 NaN   \n",
       "L-ID-2                                                 NaN   \n",
       "L-ID-3                                                 NaN   \n",
       "L-ID-4                                                 NaN   \n",
       "L-ID-5                                                 NaN   \n",
       "L-ID-6                                                 NaN   \n",
       "L-ID-7                                                 NaN   \n",
       "L-ID-8                                                 NaN   \n",
       "L-ID-9                                                 NaN   \n",
       "L-ID-10                                                NaN   \n",
       "L-ID-11                                                NaN   \n",
       "L-ID-12                                                NaN   \n",
       "L-ID-13                                                NaN   \n",
       "L-ID-14                                                NaN   \n",
       "L-ID-15                                                NaN   \n",
       "L-ID-16                                                NaN   \n",
       "L-ID-17                                                NaN   \n",
       "L-ID-18                                                NaN   \n",
       "L-ID-19                                                NaN   \n",
       "L-ID-20                                                NaN   \n",
       "L-ID-21                                                NaN   \n",
       "L-ID-22                                                NaN   \n",
       "L-ID-23                                                NaN   \n",
       "L-ID-24                                                NaN   \n",
       "\n",
       "                                                post_links  \\\n",
       "ID                                                           \n",
       "i-ID-0   https://www.indeed.com/rc/clk?jk=827870af9af1e...   \n",
       "i-ID-1   https://www.indeed.com/rc/clk?jk=993a87e42e52d...   \n",
       "i-ID-2   https://www.indeed.com/company/Wavsys/jobs/Rob...   \n",
       "i-ID-3   https://www.indeed.com/company/Circulation,-In...   \n",
       "i-ID-4   https://www.indeed.com/company/Agios-Pharmaceu...   \n",
       "i-ID-5   https://www.indeed.com/company/Index-Data/jobs...   \n",
       "i-ID-6   https://www.indeed.com/rc/clk?jk=4cc6688f09b1e...   \n",
       "i-ID-7   https://www.indeed.com/company/Positionskart/j...   \n",
       "i-ID-8   https://www.indeed.com/rc/clk?jk=7b542a241ad69...   \n",
       "i-ID-9   https://www.indeed.com/rc/clk?jk=6c8c08a72f7ce...   \n",
       "i-ID-10  https://www.indeed.com/rc/clk?jk=9634b7da90383...   \n",
       "i-ID-11  https://www.indeed.com/rc/clk?jk=99c48fcee0769...   \n",
       "i-ID-12  https://www.indeed.com/rc/clk?jk=87ebf0ef7b028...   \n",
       "i-ID-13  https://www.indeed.com/rc/clk?jk=47dd47292787d...   \n",
       "i-ID-14  https://www.indeed.com/company/Tasacom-Technol...   \n",
       "i-ID-15  https://www.indeed.com/rc/clk?jk=e64fcde704343...   \n",
       "i-ID-16  https://www.indeed.com/rc/clk?jk=6ad0a641211f3...   \n",
       "i-ID-17  https://www.indeed.com/rc/clk?jk=42045984aea51...   \n",
       "i-ID-18  https://www.indeed.com/rc/clk?jk=eab111043ccbb...   \n",
       "i-ID-19  https://www.indeed.com/rc/clk?jk=0f73c98449959...   \n",
       "i-ID-20  https://www.indeed.com/rc/clk?jk=1d04bbf47d9ad...   \n",
       "i-ID-21  https://www.indeed.com/rc/clk?jk=8d2ee06ec67ab...   \n",
       "i-ID-22  https://www.indeed.com/rc/clk?jk=e99cbc68d7608...   \n",
       "i-ID-23  https://www.indeed.com/rc/clk?jk=fae74195ddd91...   \n",
       "i-ID-24  https://www.indeed.com/rc/clk?jk=8df3f9fa51fcb...   \n",
       "L-ID-0   https://www.linkedin.com/jobs/view/senior-natu...   \n",
       "L-ID-1   https://www.linkedin.com/jobs/view/software-fi...   \n",
       "L-ID-2   https://www.linkedin.com/jobs/view/product-man...   \n",
       "L-ID-3   https://www.linkedin.com/jobs/view/analyst-hoc...   \n",
       "L-ID-4   https://www.linkedin.com/jobs/view/full-stack-...   \n",
       "L-ID-5   https://www.linkedin.com/jobs/view/full-stack-...   \n",
       "L-ID-6   https://www.linkedin.com/jobs/view/software-en...   \n",
       "L-ID-7   https://www.linkedin.com/jobs/view/php-develop...   \n",
       "L-ID-8   https://www.linkedin.com/jobs/view/full-stack-...   \n",
       "L-ID-9   https://www.linkedin.com/jobs/view/software-en...   \n",
       "L-ID-10  https://www.linkedin.com/jobs/view/lead-softwa...   \n",
       "L-ID-11  https://www.linkedin.com/jobs/view/full-stack-...   \n",
       "L-ID-12  https://www.linkedin.com/jobs/view/lead-softwa...   \n",
       "L-ID-13  https://www.linkedin.com/jobs/view/software-en...   \n",
       "L-ID-14  https://www.linkedin.com/jobs/view/lead-softwa...   \n",
       "L-ID-15  https://www.linkedin.com/jobs/view/lead-softwa...   \n",
       "L-ID-16  https://www.linkedin.com/jobs/view/lead-softwa...   \n",
       "L-ID-17  https://www.linkedin.com/jobs/view/devops-engi...   \n",
       "L-ID-18  https://www.linkedin.com/jobs/view/software-en...   \n",
       "L-ID-19  https://www.linkedin.com/jobs/view/lead-softwa...   \n",
       "L-ID-20  https://www.linkedin.com/jobs/view/lead-develo...   \n",
       "L-ID-21  https://www.linkedin.com/jobs/view/full-stack-...   \n",
       "L-ID-22  https://www.linkedin.com/jobs/view/php-develop...   \n",
       "L-ID-23  https://www.linkedin.com/jobs/view/build-relea...   \n",
       "L-ID-24  https://www.linkedin.com/jobs/view/software-en...   \n",
       "\n",
       "                                                comp_links  \\\n",
       "ID                                                           \n",
       "i-ID-0         https://www.indeed.com/cmp/Ace-Technologies   \n",
       "i-ID-1                https://www.indeed.com/cmp/Canonical   \n",
       "i-ID-2                   https://www.indeed.com/cmp/Wavsys   \n",
       "i-ID-3        https://www.indeed.com/cmp/Circulation,-Inc.   \n",
       "i-ID-4    https://www.indeed.com/cmp/Agios-Pharmaceuticals   \n",
       "i-ID-5               https://www.indeed.com/cmp/Index-Data   \n",
       "i-ID-6         https://www.indeed.com/cmp/Ace-Technologies   \n",
       "i-ID-7            https://www.indeed.com/cmp/Positionskart   \n",
       "i-ID-8   https://www.indeed.com/cmp/Foundation-Medicine...   \n",
       "i-ID-9                    https://www.indeed.com/cmp/Aetna   \n",
       "i-ID-10            https://www.indeed.com/cmp/State-Street   \n",
       "i-ID-11          https://www.indeed.com/cmp/Liberty-Mutual   \n",
       "i-ID-12       https://www.indeed.com/cmp/Mitre-Corporation   \n",
       "i-ID-13         https://www.indeed.com/cmp/Mercury-Systems   \n",
       "i-ID-14    https://www.indeed.com/cmp/Tasacom-Technologies   \n",
       "i-ID-15                     https://www.indeed.com/cmp/IBM   \n",
       "i-ID-16                   https://www.indeed.com/cmp/Onduo   \n",
       "i-ID-17                 https://www.indeed.com/cmp/Klaviyo   \n",
       "i-ID-18                 https://www.indeed.com/cmp/enEvolv   \n",
       "i-ID-19                 https://www.indeed.com/cmp/enEvolv   \n",
       "i-ID-20                     https://www.indeed.com/cmp/IBM   \n",
       "i-ID-21                 https://www.indeed.com/cmp/Klaviyo   \n",
       "i-ID-22                     https://www.indeed.com/cmp/IBM   \n",
       "i-ID-23       https://www.indeed.com/cmp/Dassault-Systèmes   \n",
       "i-ID-24   https://www.indeed.com/cmp/Continental-Resources   \n",
       "L-ID-0   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-1   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-2   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-3   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-4   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-5   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-6   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-7   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-8   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-9   https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-10  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-11  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-12  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-13  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-14  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-15  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-16  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-17  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-18  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-19  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-20  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-21  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-22  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-23  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "L-ID-24  https://www.linkedin.com/jobs?trk=jobs_chrome_...   \n",
       "\n",
       "                  company_name         l_company_name salaries_link  \\\n",
       "ID                                                                    \n",
       "i-ID-0                     IBM                    ibm                 \n",
       "i-ID-1                 Klaviyo                klaviyo                 \n",
       "i-ID-2                     IBM                    ibm                 \n",
       "i-ID-3       Dassault Systèmes      dassault systèmes                 \n",
       "i-ID-4   Continental Resources  continental resources                 \n",
       "i-ID-5                     IBM                    ibm                 \n",
       "i-ID-6                   Onduo                  onduo                 \n",
       "i-ID-7                 Klaviyo                klaviyo                 \n",
       "i-ID-8                 enEvolv                enevolv                 \n",
       "i-ID-9                 enEvolv                enevolv                 \n",
       "i-ID-10                    NaN                    NaN           NaN   \n",
       "i-ID-11                    NaN                    NaN           NaN   \n",
       "i-ID-12                    NaN                    NaN           NaN   \n",
       "i-ID-13                    NaN                    NaN           NaN   \n",
       "i-ID-14                    NaN                    NaN           NaN   \n",
       "i-ID-15                    NaN                    NaN           NaN   \n",
       "i-ID-16                    NaN                    NaN           NaN   \n",
       "i-ID-17                    NaN                    NaN           NaN   \n",
       "i-ID-18                    NaN                    NaN           NaN   \n",
       "i-ID-19                    NaN                    NaN           NaN   \n",
       "i-ID-20                    NaN                    NaN           NaN   \n",
       "i-ID-21                    NaN                    NaN           NaN   \n",
       "i-ID-22                    NaN                    NaN           NaN   \n",
       "i-ID-23                    NaN                    NaN           NaN   \n",
       "i-ID-24                    NaN                    NaN           NaN   \n",
       "L-ID-0                     NaN                    NaN           NaN   \n",
       "L-ID-1                     NaN                    NaN           NaN   \n",
       "L-ID-2                     NaN                    NaN           NaN   \n",
       "L-ID-3                     NaN                    NaN           NaN   \n",
       "L-ID-4                     NaN                    NaN           NaN   \n",
       "L-ID-5                     NaN                    NaN           NaN   \n",
       "L-ID-6                     NaN                    NaN           NaN   \n",
       "L-ID-7                     NaN                    NaN           NaN   \n",
       "L-ID-8                     NaN                    NaN           NaN   \n",
       "L-ID-9                     NaN                    NaN           NaN   \n",
       "L-ID-10                    NaN                    NaN           NaN   \n",
       "L-ID-11                    NaN                    NaN           NaN   \n",
       "L-ID-12                    NaN                    NaN           NaN   \n",
       "L-ID-13                    NaN                    NaN           NaN   \n",
       "L-ID-14                    NaN                    NaN           NaN   \n",
       "L-ID-15                    NaN                    NaN           NaN   \n",
       "L-ID-16                    NaN                    NaN           NaN   \n",
       "L-ID-17                    NaN                    NaN           NaN   \n",
       "L-ID-18                    NaN                    NaN           NaN   \n",
       "L-ID-19                    NaN                    NaN           NaN   \n",
       "L-ID-20                    NaN                    NaN           NaN   \n",
       "L-ID-21                    NaN                    NaN           NaN   \n",
       "L-ID-22                    NaN                    NaN           NaN   \n",
       "L-ID-23                    NaN                    NaN           NaN   \n",
       "L-ID-24                    NaN                    NaN           NaN   \n",
       "\n",
       "                               ...                          \\\n",
       "ID                             ...                           \n",
       "i-ID-0                         ...                           \n",
       "i-ID-1                         ...                           \n",
       "i-ID-2                         ...                           \n",
       "i-ID-3                         ...                           \n",
       "i-ID-4                         ...                           \n",
       "i-ID-5                         ...                           \n",
       "i-ID-6                         ...                           \n",
       "i-ID-7                         ...                           \n",
       "i-ID-8                         ...                           \n",
       "i-ID-9                         ...                           \n",
       "i-ID-10                        ...                           \n",
       "i-ID-11                        ...                           \n",
       "i-ID-12                        ...                           \n",
       "i-ID-13                        ...                           \n",
       "i-ID-14                        ...                           \n",
       "i-ID-15                        ...                           \n",
       "i-ID-16                        ...                           \n",
       "i-ID-17                        ...                           \n",
       "i-ID-18                        ...                           \n",
       "i-ID-19                        ...                           \n",
       "i-ID-20                        ...                           \n",
       "i-ID-21                        ...                           \n",
       "i-ID-22                        ...                           \n",
       "i-ID-23                        ...                           \n",
       "i-ID-24                        ...                           \n",
       "L-ID-0                         ...                           \n",
       "L-ID-1                         ...                           \n",
       "L-ID-2                         ...                           \n",
       "L-ID-3                         ...                           \n",
       "L-ID-4                         ...                           \n",
       "L-ID-5                         ...                           \n",
       "L-ID-6                         ...                           \n",
       "L-ID-7                         ...                           \n",
       "L-ID-8                         ...                           \n",
       "L-ID-9                         ...                           \n",
       "L-ID-10                        ...                           \n",
       "L-ID-11                        ...                           \n",
       "L-ID-12                        ...                           \n",
       "L-ID-13                        ...                           \n",
       "L-ID-14                        ...                           \n",
       "L-ID-15                        ...                           \n",
       "L-ID-16                        ...                           \n",
       "L-ID-17                        ...                           \n",
       "L-ID-18                        ...                           \n",
       "L-ID-19                        ...                           \n",
       "L-ID-20                        ...                           \n",
       "L-ID-21                        ...                           \n",
       "L-ID-22                        ...                           \n",
       "L-ID-23                        ...                           \n",
       "L-ID-24                        ...                           \n",
       "\n",
       "                                               company_pic  \\\n",
       "ID                                                           \n",
       "i-ID-0   https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "i-ID-1                                                  NA   \n",
       "i-ID-2   https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "i-ID-3   https://d2q79iu7y748jz.cloudfront.net/s/_squar...   \n",
       "i-ID-4                                                  NA   \n",
       "i-ID-5   https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
       "i-ID-6                                                  NA   \n",
       "i-ID-7                                                  NA   \n",
       "i-ID-8                                                  NA   \n",
       "i-ID-9                                                  NA   \n",
       "i-ID-10                                                NaN   \n",
       "i-ID-11                                                NaN   \n",
       "i-ID-12                                                NaN   \n",
       "i-ID-13                                                NaN   \n",
       "i-ID-14                                                NaN   \n",
       "i-ID-15                                                NaN   \n",
       "i-ID-16                                                NaN   \n",
       "i-ID-17                                                NaN   \n",
       "i-ID-18                                                NaN   \n",
       "i-ID-19                                                NaN   \n",
       "i-ID-20                                                NaN   \n",
       "i-ID-21                                                NaN   \n",
       "i-ID-22                                                NaN   \n",
       "i-ID-23                                                NaN   \n",
       "i-ID-24                                                NaN   \n",
       "L-ID-0                                                 NaN   \n",
       "L-ID-1                                                 NaN   \n",
       "L-ID-2                                                 NaN   \n",
       "L-ID-3                                                 NaN   \n",
       "L-ID-4                                                 NaN   \n",
       "L-ID-5                                                 NaN   \n",
       "L-ID-6                                                 NaN   \n",
       "L-ID-7                                                 NaN   \n",
       "L-ID-8                                                 NaN   \n",
       "L-ID-9                                                 NaN   \n",
       "L-ID-10                                                NaN   \n",
       "L-ID-11                                                NaN   \n",
       "L-ID-12                                                NaN   \n",
       "L-ID-13                                                NaN   \n",
       "L-ID-14                                                NaN   \n",
       "L-ID-15                                                NaN   \n",
       "L-ID-16                                                NaN   \n",
       "L-ID-17                                                NaN   \n",
       "L-ID-18                                                NaN   \n",
       "L-ID-19                                                NaN   \n",
       "L-ID-20                                                NaN   \n",
       "L-ID-21                                                NaN   \n",
       "L-ID-22                                                NaN   \n",
       "L-ID-23                                                NaN   \n",
       "L-ID-24                                                NaN   \n",
       "\n",
       "                    location  \\\n",
       "ID                             \n",
       "i-ID-0   Cambridge, MA 02139   \n",
       "i-ID-1            Boston, MA   \n",
       "i-ID-2   Littleton, MA 01460   \n",
       "i-ID-3           Waltham, MA   \n",
       "i-ID-4     Bedford, MA 01730   \n",
       "i-ID-5   Littleton, MA 01460   \n",
       "i-ID-6      Newton, MA 02458   \n",
       "i-ID-7            Boston, MA   \n",
       "i-ID-8     Medford, MA 02155   \n",
       "i-ID-9     Medford, MA 02155   \n",
       "i-ID-10                  NaN   \n",
       "i-ID-11                  NaN   \n",
       "i-ID-12                  NaN   \n",
       "i-ID-13                  NaN   \n",
       "i-ID-14                  NaN   \n",
       "i-ID-15                  NaN   \n",
       "i-ID-16                  NaN   \n",
       "i-ID-17                  NaN   \n",
       "i-ID-18                  NaN   \n",
       "i-ID-19                  NaN   \n",
       "i-ID-20                  NaN   \n",
       "i-ID-21                  NaN   \n",
       "i-ID-22                  NaN   \n",
       "i-ID-23                  NaN   \n",
       "i-ID-24                  NaN   \n",
       "L-ID-0                   NaN   \n",
       "L-ID-1                   NaN   \n",
       "L-ID-2                   NaN   \n",
       "L-ID-3                   NaN   \n",
       "L-ID-4                   NaN   \n",
       "L-ID-5                   NaN   \n",
       "L-ID-6                   NaN   \n",
       "L-ID-7                   NaN   \n",
       "L-ID-8                   NaN   \n",
       "L-ID-9                   NaN   \n",
       "L-ID-10                  NaN   \n",
       "L-ID-11                  NaN   \n",
       "L-ID-12                  NaN   \n",
       "L-ID-13                  NaN   \n",
       "L-ID-14                  NaN   \n",
       "L-ID-15                  NaN   \n",
       "L-ID-16                  NaN   \n",
       "L-ID-17                  NaN   \n",
       "L-ID-18                  NaN   \n",
       "L-ID-19                  NaN   \n",
       "L-ID-20                  NaN   \n",
       "L-ID-21                  NaN   \n",
       "L-ID-22                  NaN   \n",
       "L-ID-23                  NaN   \n",
       "L-ID-24                  NaN   \n",
       "\n",
       "                                                  comp_loc  \\\n",
       "ID                                                           \n",
       "i-ID-0                            IBM, Cambridge, MA 02139   \n",
       "i-ID-1                                 Klaviyo, Boston, MA   \n",
       "i-ID-2                            IBM, Littleton, MA 01460   \n",
       "i-ID-3                      Dassault Systèmes, Waltham, MA   \n",
       "i-ID-4            Continental Resources, Bedford, MA 01730   \n",
       "i-ID-5                            IBM, Littleton, MA 01460   \n",
       "i-ID-6                             Onduo, Newton, MA 02458   \n",
       "i-ID-7                                 Klaviyo, Boston, MA   \n",
       "i-ID-8                          enEvolv, Medford, MA 02155   \n",
       "i-ID-9                          enEvolv, Medford, MA 02155   \n",
       "i-ID-10                                                NaN   \n",
       "i-ID-11                                                NaN   \n",
       "i-ID-12                                                NaN   \n",
       "i-ID-13                                                NaN   \n",
       "i-ID-14                                                NaN   \n",
       "i-ID-15                                                NaN   \n",
       "i-ID-16                                                NaN   \n",
       "i-ID-17                                                NaN   \n",
       "i-ID-18                                                NaN   \n",
       "i-ID-19                                                NaN   \n",
       "i-ID-20                                                NaN   \n",
       "i-ID-21                                                NaN   \n",
       "i-ID-22                                                NaN   \n",
       "i-ID-23                                                NaN   \n",
       "i-ID-24                                                NaN   \n",
       "L-ID-0   Telepathy Labs, Boston, Massachusetts, United ...   \n",
       "L-ID-1   MKS Instruments, 90 Industrial Way, Wilmington...   \n",
       "L-ID-2              InterSystems, Cambridge, Massachusetts   \n",
       "L-ID-3                       Boston Bruins, Boston, MA, US   \n",
       "L-ID-4           Robert Half Technology, Cambridge, MA, US   \n",
       "L-ID-5                                Hired, Acton, MA, US   \n",
       "L-ID-6                              Hired, Ashland, MA, US   \n",
       "L-ID-7                               Hired, Wenham, MA, US   \n",
       "L-ID-8                             Hired, Humarock, MA, US   \n",
       "L-ID-9                               Hired, Easton, MA, US   \n",
       "L-ID-10                            Hired, Nonantum, MA, US   \n",
       "L-ID-11                            Hired, Weymouth, MA, US   \n",
       "L-ID-12                        Hired, East Walpole, MA, US   \n",
       "L-ID-13                       Hired, North Andover, MA, US   \n",
       "L-ID-14                             Hired, Norfolk, MA, US   \n",
       "L-ID-15                            Hired, Sherborn, MA, US   \n",
       "L-ID-16                              Hired, Newton, MA, US   \n",
       "L-ID-17                              Hired, Boston, MA, US   \n",
       "L-ID-18                           Hired, Greenbush, MA, US   \n",
       "L-ID-19                                Hired, Avon, MA, US   \n",
       "L-ID-20                         Hired, Babson Park, MA, US   \n",
       "L-ID-21                      Hired, North Pembroke, MA, US   \n",
       "L-ID-22                               Hired, Essex, MA, US   \n",
       "L-ID-23                  Hired, Newton Upper Falls, MA, US   \n",
       "L-ID-24                               Hired, Salem, MA, US   \n",
       "\n",
       "                                                      body    post_time  \\\n",
       "ID                                                                        \n",
       "i-ID-0   Job Description\\nIBM Research is the innovatio...  6 hours ago   \n",
       "i-ID-1   We love programming and the excitement that co...  7 hours ago   \n",
       "i-ID-2   Job Description\\nJob Description\\nResponsibili...  6 hours ago   \n",
       "i-ID-3   Exa part of the family of Simulia products, ba...  8 hours ago   \n",
       "i-ID-4   Outperform your competition; consider becoming...  6 hours ago   \n",
       "i-ID-5   Job Description\\nAre you interested in pursuin...  6 hours ago   \n",
       "i-ID-6   Responsibilities and Duties:\\nOnduo is looking...  8 hours ago   \n",
       "i-ID-7   We love programming and the excitement that co...  7 hours ago   \n",
       "i-ID-8   We are seeking a Microfluidics Engineer to joi...  6 hours ago   \n",
       "i-ID-9   The Bioinformatician will be a member of the C...  6 hours ago   \n",
       "i-ID-10                                                NaN          NaN   \n",
       "i-ID-11                                                NaN          NaN   \n",
       "i-ID-12                                                NaN          NaN   \n",
       "i-ID-13                                                NaN          NaN   \n",
       "i-ID-14                                                NaN          NaN   \n",
       "i-ID-15                                                NaN          NaN   \n",
       "i-ID-16                                                NaN          NaN   \n",
       "i-ID-17                                                NaN          NaN   \n",
       "i-ID-18                                                NaN          NaN   \n",
       "i-ID-19                                                NaN          NaN   \n",
       "i-ID-20                                                NaN          NaN   \n",
       "i-ID-21                                                NaN          NaN   \n",
       "i-ID-22                                                NaN          NaN   \n",
       "i-ID-23                                                NaN          NaN   \n",
       "i-ID-24                                                NaN          NaN   \n",
       "L-ID-0                                                 NaN          NaN   \n",
       "L-ID-1                                                 NaN          NaN   \n",
       "L-ID-2                                                 NaN          NaN   \n",
       "L-ID-3                                                 NaN          NaN   \n",
       "L-ID-4                                                 NaN          NaN   \n",
       "L-ID-5                                                 NaN          NaN   \n",
       "L-ID-6                                                 NaN          NaN   \n",
       "L-ID-7                                                 NaN          NaN   \n",
       "L-ID-8                                                 NaN          NaN   \n",
       "L-ID-9                                                 NaN          NaN   \n",
       "L-ID-10                                                NaN          NaN   \n",
       "L-ID-11                                                NaN          NaN   \n",
       "L-ID-12                                                NaN          NaN   \n",
       "L-ID-13                                                NaN          NaN   \n",
       "L-ID-14                                                NaN          NaN   \n",
       "L-ID-15                                                NaN          NaN   \n",
       "L-ID-16                                                NaN          NaN   \n",
       "L-ID-17                                                NaN          NaN   \n",
       "L-ID-18                                                NaN          NaN   \n",
       "L-ID-19                                                NaN          NaN   \n",
       "L-ID-20                                                NaN          NaN   \n",
       "L-ID-21                                                NaN          NaN   \n",
       "L-ID-22                                                NaN          NaN   \n",
       "L-ID-23                                                NaN          NaN   \n",
       "L-ID-24                                                NaN          NaN   \n",
       "\n",
       "        pulldates                                          locations  \\\n",
       "ID                                                                     \n",
       "i-ID-0        NaN                                                NaN   \n",
       "i-ID-1        NaN                                                NaN   \n",
       "i-ID-2        NaN                                                NaN   \n",
       "i-ID-3        NaN                                                NaN   \n",
       "i-ID-4        NaN                                                NaN   \n",
       "i-ID-5        NaN                                                NaN   \n",
       "i-ID-6        NaN                                                NaN   \n",
       "i-ID-7        NaN                                                NaN   \n",
       "i-ID-8        NaN                                                NaN   \n",
       "i-ID-9        NaN                                                NaN   \n",
       "i-ID-10       NaN                                                NaN   \n",
       "i-ID-11       NaN                                                NaN   \n",
       "i-ID-12       NaN                                                NaN   \n",
       "i-ID-13       NaN                                                NaN   \n",
       "i-ID-14       NaN                                                NaN   \n",
       "i-ID-15       NaN                                                NaN   \n",
       "i-ID-16       NaN                                                NaN   \n",
       "i-ID-17       NaN                                                NaN   \n",
       "i-ID-18       NaN                                                NaN   \n",
       "i-ID-19       NaN                                                NaN   \n",
       "i-ID-20       NaN                                                NaN   \n",
       "i-ID-21       NaN                                                NaN   \n",
       "i-ID-22       NaN                                                NaN   \n",
       "i-ID-23       NaN                                                NaN   \n",
       "i-ID-24       NaN                                                NaN   \n",
       "L-ID-0   11162018               Boston, Massachusetts, United States   \n",
       "L-ID-1   11162018  90 Industrial Way, Wilmington, Massachusetts 0...   \n",
       "L-ID-2   11162018                           Cambridge, Massachusetts   \n",
       "L-ID-3   11162018                                     Boston, MA, US   \n",
       "L-ID-4   11162018                                  Cambridge, MA, US   \n",
       "L-ID-5   11162018                                      Acton, MA, US   \n",
       "L-ID-6   11162018                                    Ashland, MA, US   \n",
       "L-ID-7   11162018                                     Wenham, MA, US   \n",
       "L-ID-8   11162018                                   Humarock, MA, US   \n",
       "L-ID-9   11162018                                     Easton, MA, US   \n",
       "L-ID-10  11162018                                   Nonantum, MA, US   \n",
       "L-ID-11  11162018                                   Weymouth, MA, US   \n",
       "L-ID-12  11162018                               East Walpole, MA, US   \n",
       "L-ID-13  11162018                              North Andover, MA, US   \n",
       "L-ID-14  11162018                                    Norfolk, MA, US   \n",
       "L-ID-15  11162018                                   Sherborn, MA, US   \n",
       "L-ID-16  11162018                                     Newton, MA, US   \n",
       "L-ID-17  11162018                                     Boston, MA, US   \n",
       "L-ID-18  11162018                                  Greenbush, MA, US   \n",
       "L-ID-19  11162018                                       Avon, MA, US   \n",
       "L-ID-20  11162018                                Babson Park, MA, US   \n",
       "L-ID-21  11162018                             North Pembroke, MA, US   \n",
       "L-ID-22  11162018                                      Essex, MA, US   \n",
       "L-ID-23  11162018                         Newton Upper Falls, MA, US   \n",
       "L-ID-24  11162018                                      Salem, MA, US   \n",
       "\n",
       "                                                     descr ezapply  \\\n",
       "ID                                                                   \n",
       "i-ID-0                                                 NaN     NaN   \n",
       "i-ID-1                                                 NaN     NaN   \n",
       "i-ID-2                                                 NaN     NaN   \n",
       "i-ID-3                                                 NaN     NaN   \n",
       "i-ID-4                                                 NaN     NaN   \n",
       "i-ID-5                                                 NaN     NaN   \n",
       "i-ID-6                                                 NaN     NaN   \n",
       "i-ID-7                                                 NaN     NaN   \n",
       "i-ID-8                                                 NaN     NaN   \n",
       "i-ID-9                                                 NaN     NaN   \n",
       "i-ID-10                                                NaN     NaN   \n",
       "i-ID-11                                                NaN     NaN   \n",
       "i-ID-12                                                NaN     NaN   \n",
       "i-ID-13                                                NaN     NaN   \n",
       "i-ID-14                                                NaN     NaN   \n",
       "i-ID-15                                                NaN     NaN   \n",
       "i-ID-16                                                NaN     NaN   \n",
       "i-ID-17                                                NaN     NaN   \n",
       "i-ID-18                                                NaN     NaN   \n",
       "i-ID-19                                                NaN     NaN   \n",
       "i-ID-20                                                NaN     NaN   \n",
       "i-ID-21                                                NaN     NaN   \n",
       "i-ID-22                                                NaN     NaN   \n",
       "i-ID-23                                                NaN     NaN   \n",
       "i-ID-24                                                NaN     NaN   \n",
       "L-ID-0   We are seeking a dynamic, passionate and exper...           \n",
       "L-ID-1   MKS Instruments, a worldwide leader in providi...           \n",
       "L-ID-2   It includes hands-on data science technical wo...           \n",
       "L-ID-3   Problem-solving skills – must be able to asses...           \n",
       "L-ID-4   Robert Half Technology is searching for a cand...           \n",
       "L-ID-5   You will also develop and maintain web applica...           \n",
       "L-ID-6   You will also develop and maintain web applica...           \n",
       "L-ID-7   You will also develop and maintain web applica...           \n",
       "L-ID-8   You will also develop and maintain web applica...           \n",
       "L-ID-9   You will also develop and maintain web applica...           \n",
       "L-ID-10  You will also develop and maintain web applica...           \n",
       "L-ID-11  You will also develop and maintain web applica...           \n",
       "L-ID-12  You will also develop and maintain web applica...           \n",
       "L-ID-13  Would you like to build apps for a range of iO...           \n",
       "L-ID-14  You will also develop and maintain web applica...           \n",
       "L-ID-15  You will also develop and maintain web applica...           \n",
       "L-ID-16  You will also develop and maintain web applica...           \n",
       "L-ID-17  Responsibilities Working in an agile developme...           \n",
       "L-ID-18  You will also develop and maintain web applica...           \n",
       "L-ID-19  You will also develop and maintain web applica...           \n",
       "L-ID-20  You will also develop and maintain web applica...           \n",
       "L-ID-21  You will also develop and maintain web applica...           \n",
       "L-ID-22  You will also develop and maintain web applica...           \n",
       "L-ID-23  Are you interested in building flexibility and...           \n",
       "L-ID-24  You will also develop and maintain web applica...           \n",
       "\n",
       "                                              company_pics  \n",
       "ID                                                          \n",
       "i-ID-0                                                 NaN  \n",
       "i-ID-1                                                 NaN  \n",
       "i-ID-2                                                 NaN  \n",
       "i-ID-3                                                 NaN  \n",
       "i-ID-4                                                 NaN  \n",
       "i-ID-5                                                 NaN  \n",
       "i-ID-6                                                 NaN  \n",
       "i-ID-7                                                 NaN  \n",
       "i-ID-8                                                 NaN  \n",
       "i-ID-9                                                 NaN  \n",
       "i-ID-10                                                NaN  \n",
       "i-ID-11                                                NaN  \n",
       "i-ID-12                                                NaN  \n",
       "i-ID-13                                                NaN  \n",
       "i-ID-14                                                NaN  \n",
       "i-ID-15                                                NaN  \n",
       "i-ID-16                                                NaN  \n",
       "i-ID-17                                                NaN  \n",
       "i-ID-18                                                NaN  \n",
       "i-ID-19                                                NaN  \n",
       "i-ID-20                                                NaN  \n",
       "i-ID-21                                                NaN  \n",
       "i-ID-22                                                NaN  \n",
       "i-ID-23                                                NaN  \n",
       "i-ID-24                                                NaN  \n",
       "L-ID-0   https://media.licdn.com/dms/image/C4E0BAQFChPp...  \n",
       "L-ID-1   https://media.licdn.com/dms/image/C4D0BAQGUMM1...  \n",
       "L-ID-2   https://media.licdn.com/dms/image/C4E0BAQFhEni...  \n",
       "L-ID-3   https://media.licdn.com/dms/image/C560BAQH8H4U...  \n",
       "L-ID-4   https://media.licdn.com/dms/image/C4D0BAQEXLtt...  \n",
       "L-ID-5                                                None  \n",
       "L-ID-6                                                None  \n",
       "L-ID-7                                                None  \n",
       "L-ID-8                                                None  \n",
       "L-ID-9                                                None  \n",
       "L-ID-10                                               None  \n",
       "L-ID-11                                               None  \n",
       "L-ID-12                                               None  \n",
       "L-ID-13                                               None  \n",
       "L-ID-14                                               None  \n",
       "L-ID-15                                               None  \n",
       "L-ID-16                                               None  \n",
       "L-ID-17                                               None  \n",
       "L-ID-18                                               None  \n",
       "L-ID-19                                               None  \n",
       "L-ID-20                                               None  \n",
       "L-ID-21                                               None  \n",
       "L-ID-22                                               None  \n",
       "L-ID-23                                               None  \n",
       "L-ID-24                                               None  \n",
       "\n",
       "[50 rows x 22 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch = ult_scrap(**{\n",
    "    'results_per_site' : 25,\n",
    "    'job_title' : 'python',\n",
    "    'city' : 'boston',\n",
    "    'site_list' : ['indeed', 'linkedin'],\n",
    "    'linked_in_username' : 'USERNAME',\n",
    "    'linked_in_password' : 'PASSWORD',\n",
    "    'chromedriver_location' : u'/chromedriver.exe',\n",
    "    'api_key' : 'APIKEY'\n",
    "})\n",
    "fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pulldate', 'companies', 'l_companies', 'titles', 'description',\n",
       "       'post_links', 'comp_links', 'company_name', 'l_company_name',\n",
       "       'salaries_link', 'reviews_link', 'jobtitle', 'company_pic', 'location',\n",
       "       'comp_loc', 'body', 'post_time', 'pulldates', 'locations', 'descr',\n",
       "       'ezapply', 'company_pics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/jobs?q=python&l=worcester&start=0&sort=date&radius=25\n",
      "10 \n",
      " 10 \n",
      " 10 \n",
      " 10 \n",
      " 10\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "                        company       rating  \\\n",
      "0                  Diverse Lynx          4.8   \n",
      "1                   PerkinElmer          3.8   \n",
      "2                       Marvell          3.4   \n",
      "3                       Marvell          3.4   \n",
      "4                          Bose          4.2   \n",
      "5                          Bose          4.2   \n",
      "6                          Bose          4.2   \n",
      "7                          Bose          4.2   \n",
      "8                       Marvell          3.4   \n",
      "9                       Marvell          3.4   \n",
      "10                         Dell          4.0   \n",
      "11                        Intel          4.1   \n",
      "12  The Hanover Insurance Group          3.8   \n",
      "13           Spill Center, Inc.  Not ranked.   \n",
      "\n",
      "                                        salaries_link  \\\n",
      "0   https://www.indeed.com/cmp/Diverse Lynx/salaries/   \n",
      "1    https://www.indeed.com/cmp/PerkinElmer/salaries/   \n",
      "2        https://www.indeed.com/cmp/Marvell/salaries/   \n",
      "3        https://www.indeed.com/cmp/Marvell/salaries/   \n",
      "4           https://www.indeed.com/cmp/Bose/salaries/   \n",
      "5           https://www.indeed.com/cmp/Bose/salaries/   \n",
      "6           https://www.indeed.com/cmp/Bose/salaries/   \n",
      "7           https://www.indeed.com/cmp/Bose/salaries/   \n",
      "8        https://www.indeed.com/cmp/Marvell/salaries/   \n",
      "9        https://www.indeed.com/cmp/Marvell/salaries/   \n",
      "10          https://www.indeed.com/cmp/Dell/salaries/   \n",
      "11         https://www.indeed.com/cmp/Intel/salaries/   \n",
      "12  https://www.indeed.com/cmp/The Hanover Insuran...   \n",
      "13  https://www.indeed.com/cmp/Spill Center, Inc./...   \n",
      "\n",
      "                                         reviews_link  \\\n",
      "0    https://www.indeed.com/cmp/Diverse Lynx/reviews/   \n",
      "1     https://www.indeed.com/cmp/PerkinElmer/reviews/   \n",
      "2         https://www.indeed.com/cmp/Marvell/reviews/   \n",
      "3         https://www.indeed.com/cmp/Marvell/reviews/   \n",
      "4            https://www.indeed.com/cmp/Bose/reviews/   \n",
      "5            https://www.indeed.com/cmp/Bose/reviews/   \n",
      "6            https://www.indeed.com/cmp/Bose/reviews/   \n",
      "7            https://www.indeed.com/cmp/Bose/reviews/   \n",
      "8         https://www.indeed.com/cmp/Marvell/reviews/   \n",
      "9         https://www.indeed.com/cmp/Marvell/reviews/   \n",
      "10           https://www.indeed.com/cmp/Dell/reviews/   \n",
      "11          https://www.indeed.com/cmp/Intel/reviews/   \n",
      "12  https://www.indeed.com/cmp/The Hanover Insuran...   \n",
      "13  https://www.indeed.com/cmp/Spill Center, Inc./...   \n",
      "\n",
      "                                             title      posttime  \\\n",
      "0                                     Hadoop Admin   8 hours ago   \n",
      "1                        Senior Software Developer  17 hours ago   \n",
      "2                                RTL Design Intern     1 day ago   \n",
      "3                   Intern - Verification Engineer    3 days ago   \n",
      "4                               Sr. Data Scientist     1 day ago   \n",
      "5                    Senior QA Automation Engineer    2 days ago   \n",
      "6                               Sr. Data Scientist     1 day ago   \n",
      "7                    Senior QA Automation Engineer    2 days ago   \n",
      "8                                RTL Design Intern     1 day ago   \n",
      "9                   Intern - Verification Engineer    3 days ago   \n",
      "10                                             NaN           NaN   \n",
      "11  Validation Infrastructure Development Engineer    3 days ago   \n",
      "12                        Associate Data Scientist    4 days ago   \n",
      "13                   Junior Applications Developer    4 days ago   \n",
      "\n",
      "                 location                                        company_pic  \\\n",
      "0          Woonsocket, RI  https://d2q79iu7y748jz.cloudfront.net/s/_squar...   \n",
      "1           Hopkinton, MA  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "2   Marlborough, MA 01752  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "3   Marlborough, MA 01752  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "4    Framingham, MA 01701  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "5    Framingham, MA 01701  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "6    Framingham, MA 01701  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "7    Framingham, MA 01701  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "8   Marlborough, MA 01752  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "9   Marlborough, MA 01752  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "10                    NaN                                                NaN   \n",
      "11       Hudson, MA 01749  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "12    Worcester, MA 01653  https://d2q79iu7y748jz.cloudfront.net/s/_logo/...   \n",
      "13       Hudson, MA 01749                                                 NA   \n",
      "\n",
      "                                            body_text  sID    site  \\\n",
      "0   Contract\\nJob Title: Hadoop Admin\\n\\nJob Locat...  sID  indeed   \n",
      "1   Responsibilities:\\nParticipate in the design, ...  sID  indeed   \n",
      "2   Internship\\nRTL DESIGNER - INTERN\\n\\nContribut...  sID  indeed   \n",
      "3   Internship\\nResponsibilities:\\nWriting program...  sID  indeed   \n",
      "4   Data science group in Consumer Electronics bus...  sID  indeed   \n",
      "5   Think you know Bose? Look closer.\\n\\nWe’ve spe...  sID  indeed   \n",
      "6   Data science group in Consumer Electronics bus...  sID  indeed   \n",
      "7   Think you know Bose? Look closer.\\n\\nWe’ve spe...  sID  indeed   \n",
      "8   Internship\\nRTL DESIGNER - INTERN\\n\\nContribut...  sID  indeed   \n",
      "9   Internship\\nResponsibilities:\\nWriting program...  sID  indeed   \n",
      "10                                                NaN  NaN     NaN   \n",
      "11  Job Description\\nJob DescriptionAre you ready ...  sID  indeed   \n",
      "12  Overview\\n\\nOur Data Science department is see...  sID  indeed   \n",
      "13  Our Company\\n\\nSpill Center is an environmenta...  sID  indeed   \n",
      "\n",
      "                                              summary  \\\n",
      "0   Python, shell scripting, SQL (preferably Terad...   \n",
      "1   Fluency in C# and at least one additional prog...   \n",
      "2   RTL DESIGNER - INTERN Contribute as a design e...   \n",
      "3   Some experience with scripting languages like ...   \n",
      "4   Proficiency in data science software developme...   \n",
      "5   Mastery of Python, Perl, JavaScript, or simila...   \n",
      "6   Proficiency in data science software developme...   \n",
      "7   Mastery of Python, Perl, JavaScript, or simila...   \n",
      "8   RTL DESIGNER - INTERN Contribute as a design e...   \n",
      "9   Some experience with scripting languages like ...   \n",
      "10                                                NaN   \n",
      "11  Perl, Python, or other scripting languages exp...   \n",
      "12  SAS, SQL, VBA, R, Python. Our Data Science dep...   \n",
      "13  Ability to program in at least one programming...   \n",
      "\n",
      "                                           post_links  \\\n",
      "0   https://www.indeed.com/rc/clk?jk=033c8e70396f9...   \n",
      "1   https://www.indeed.com/rc/clk?jk=b1d1505969f0c...   \n",
      "2   https://www.indeed.com/rc/clk?jk=79655463fc574...   \n",
      "3   https://www.indeed.com/rc/clk?jk=da4f6ebaf1888...   \n",
      "4   https://www.indeed.com/rc/clk?jk=6ea87a474808e...   \n",
      "5   https://www.indeed.com/rc/clk?jk=2d2b7d4aef088...   \n",
      "6   https://www.indeed.com/rc/clk?jk=6ea87a474808e...   \n",
      "7   https://www.indeed.com/rc/clk?jk=2d2b7d4aef088...   \n",
      "8   https://www.indeed.com/rc/clk?jk=79655463fc574...   \n",
      "9   https://www.indeed.com/rc/clk?jk=da4f6ebaf1888...   \n",
      "10                                                NaN   \n",
      "11  https://www.indeed.com/rc/clk?jk=fbc2fffa62c1e...   \n",
      "12  https://www.indeed.com/rc/clk?jk=f762a1ef49af0...   \n",
      "13  https://www.indeed.com/rc/clk?jk=a525724756819...   \n",
      "\n",
      "                                           comp_links  \n",
      "0             https://www.indeed.com/cmp/Diverse-Lynx  \n",
      "1              https://www.indeed.com/cmp/PerkinElmer  \n",
      "2                  https://www.indeed.com/cmp/Marvell  \n",
      "3                  https://www.indeed.com/cmp/Marvell  \n",
      "4                     https://www.indeed.com/cmp/Bose  \n",
      "5                     https://www.indeed.com/cmp/Bose  \n",
      "6                     https://www.indeed.com/cmp/Bose  \n",
      "7                     https://www.indeed.com/cmp/Bose  \n",
      "8                  https://www.indeed.com/cmp/Marvell  \n",
      "9                  https://www.indeed.com/cmp/Marvell  \n",
      "10                                                NaN  \n",
      "11                   https://www.indeed.com/cmp/Intel  \n",
      "12  https://www.indeed.com/cmp/The-Hanover-Insuran...  \n",
      "13      https://www.indeed.com/cmp/Spill-Center,-Inc.  \n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument('--log-level=3')\n",
    "wd = webdriver.Chrome(scrap_params['chromedriver_location'], options=options)\n",
    "url = 'https://www.indeed.com/jobs?q=python&l=worcester&start=0&sort=date&radius=25'\n",
    "print(url)\n",
    "wd.get(url)\n",
    "companies = []\n",
    "\n",
    "#companies = [company.text for company in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']\")]\n",
    "companies = [company.text for company in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='company']\")]\n",
    "titles = [title.text for title in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//h2[@class='jobtitle']\")]\n",
    "description = [description.text for description in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//span[@class='summary']\")]\n",
    "post_links = [post_link.get_attribute('href') for post_link in wd.find_elements_by_xpath(\"//div[@data-tn-component='organicJob']//h2[@class='jobtitle']//a\")]\n",
    "comp_links = ['https://www.indeed.com/cmp/' + str(company).replace(' ', '-') for company in companies]\n",
    "\n",
    "tmp_df = pd.DataFrame({'ID' : 'ID', 'site' : 'indeed', 'title' : titles, 'company' : companies, 'summary' : description, 'post_links' : post_links, 'comp_links' : comp_links})\n",
    "\n",
    "comp_list = []\n",
    "for link in comp_links:\n",
    "    wd.get(link)\n",
    "    company_name = wd.find_element_by_xpath(\"//div[@class='cmp-company-name-container']\").text\n",
    "    try:\n",
    "        average_comp_rating = wd.find_element_by_xpath(\"//span[@class='cmp-header-rating-average']\").text\n",
    "    except:\n",
    "        average_comp_rating = 'Not ranked.'\n",
    "    salaries_link = 'https://www.indeed.com/cmp/' + company_name + '/salaries/'\n",
    "    reviews_link = 'https://www.indeed.com/cmp/' + company_name + '/reviews/'\n",
    "    comp_list.append([company_name, average_comp_rating, salaries_link, reviews_link])\n",
    "comp_df = pd.DataFrame(comp_list, columns=['company', 'rating', 'salaries_link', 'reviews_link'])\n",
    "\n",
    "post_list = []\n",
    "for link in post_links:\n",
    "    wd.get(link)\n",
    "    jobtitle = wd.find_element_by_xpath(\"//h3[contains(@class, 'jobsearch-JobInfoHeader-title')]\").text\n",
    "    #jobtitle = wd.find_element_by_xpath(\"//h3[@class='jobsearch-JobInfoHeader-title']\").text\n",
    "    #company_name = wd.find_element_by_xpath(\"//div[@class='icl-u-lg-mr--sm icl-u-xs-mr--xs']\").text\n",
    "    try:\n",
    "        company_pic = wd.find_element_by_xpath(\"//img[@class='jobsearch-CompanyAvatar-image']\").get_attribute('src')\n",
    "    except:\n",
    "        company_pic = 'NA'\n",
    "    line = wd.find_element_by_xpath(\"//div[contains(@class, 'jobsearch-InlineCompanyRating')]\").text\n",
    "    location = line.split('\\n')[2]\n",
    "    company_name = line.split('\\n')[0]\n",
    "    body = wd.find_element_by_xpath(\"//div[contains(@class, 'jobsearch-JobComponent-description')]\").text\n",
    "    post_time = wd.find_element_by_xpath(\"//div[@class='jobsearch-JobMetadataFooter']\").text.split('-')[1].strip()\n",
    "    post_list.append([jobtitle, company_name, post_time, location, company_pic, body])\n",
    "post_df = pd.DataFrame(post_list, columns=['title', 'company', 'posttime', 'location', 'company_pic', 'body_text'])\n",
    "job_df = comp_df.merge(post_df, on='company', how='left')\n",
    "job_df = job_df.merge(tmp_df, on=['company', 'title'], how='left')\n",
    "wd.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              https://www.indeed.com/cmp/Diverse-Lynx\n",
       "1               https://www.indeed.com/cmp/PerkinElmer\n",
       "2                   https://www.indeed.com/cmp/Marvell\n",
       "3                      https://www.indeed.com/cmp/Bose\n",
       "4                      https://www.indeed.com/cmp/Bose\n",
       "5                   https://www.indeed.com/cmp/Marvell\n",
       "6                     https://www.indeed.com/cmp/Intel\n",
       "7                      https://www.indeed.com/cmp/DELL\n",
       "8    https://www.indeed.com/cmp/The-Hanover-Insuran...\n",
       "9        https://www.indeed.com/cmp/Spill-Center,-Inc.\n",
       "Name: comp_links, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df['comp_links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tex_output(fetch, suffix=''):\n",
    "    fetch_df = fetch\n",
    "    #fetch_dict = fetch[1]\n",
    "    map_list = []\n",
    "    content = r'''\\UseRawInputEncoding%\n",
    "\\documentclass{{article}}%\n",
    "\\usepackage[T1]{{fontenc}}%\n",
    "\\usepackage[utf8]{{inputenc}}%\n",
    "\\inputencoding{utf8}\n",
    "\\usepackage{{lmodern}}%\n",
    "\\usepackage{graphicx}\n",
    "\\usepackage{{textcomp}}%\n",
    "\\usepackage{{lastpage}}%\n",
    "\n",
    "\\begin{document}%\n",
    "\\normalsize%'''\n",
    "    \n",
    "    for index, row in fetch_df.iterrows():\n",
    "        print(index)\n",
    "        print(row['map_url'])\n",
    "        map_file_name = str(index) + '.jpg'\n",
    "        map_list.append(map_file_name)\n",
    "        urllib.request.urlretrieve(str(row['map_url']), map_file_name)\n",
    "        content = content + r'''\n",
    "\\section{{{jobtitle}}}%\n",
    "\\subsection{{{comploc}}}\n",
    "{{{address}}}\n",
    "{{{distance}}}\n",
    "{{{duration}}}\n",
    "\n",
    "\n",
    "\\begin{{figure}}\n",
    "\\includegraphics{{{map_file_name}}}\n",
    "\\end{{figure}}\n",
    "\n",
    "\\subsection{{Salary}}%\n",
    "{{{salary}}}\n",
    "\n",
    "\\subsection{{Link}}%\n",
    "{{{link}}}\n",
    "\n",
    "\\newpage\n",
    "\n",
    "\n",
    "'''.format(**{'jobtitle': row['title'], 'salary' : row['salary'], 'comploc' : row['comp_loc'], 'address' : row['address'], 'distance' : row['distance'], \n",
    "              'duration' : row['duration'], 'link' : row['link'], 'map_file_name' : map_file_name}).replace('&', '\\&').replace('$', '\\$').replace('#', '\\#').replace('|', '').replace('_', '\\_')        \n",
    "        filename = 'job_scrap_output' + suffix + '.tex'\n",
    "\n",
    "    content = content + '''\n",
    "\\end{document}%'''\n",
    "    with open(filename,'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    cmd = ['pdflatex', filename]\n",
    "    subprocess.check_output(cmd)\n",
    "\n",
    "    os.unlink('job_scrap_output.log')\n",
    "    os.unlink('job_scrap_output.aux')\n",
    "    for file in map_list:\n",
    "        os.unlink(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tex_output(fetch, suffix=''):\n",
    "    fetch_df = fetch\n",
    "    #fetch_dict = fetch[1]\n",
    "    map_list = []\n",
    "    content = r'''\\documentclass[letterpaper,12pt,fleqn]{{article}}\n",
    "\\usepackage{{fancyhdr}}\n",
    "\\usepackage{{datetime}}\n",
    "\\usepackage{{hyperref}}\n",
    "\n",
    "% Insert Title Page Info Below\n",
    "\n",
    "\\newcommand{\\Titles}{Job ScrapyBoi} %\n",
    "\\newcommand{\\cityset}{Boston} %\n",
    "\\newcommand{\\jobset}{Data Science} %\n",
    "\\newcommand{\\authors}{Matt and Chris} %\n",
    "\\newcommand{\\sources}{Indeed, LinkedIn, StackOverflow} %\n",
    "\\newcommand{\\lastwords}{End of Results} %\n",
    "\n",
    "% Margins and Footer Style\n",
    "\\setlength{\\topmargin}{0cm} %\n",
    "\\setlength{\\textheight}{9.25in} %\n",
    "\\setlength{\\oddsidemargin}{0.0in}\n",
    "\\setlength{\\evensidemargin}{0.0in}\n",
    "\\setlength{\\textwidth}{16cm}\n",
    "\\pagestyle{fancy}\n",
    "\\lhead{{}} \n",
    "\\chead{{}} \n",
    "\\rhead{{}} \n",
    "\\lfoot{{}} \n",
    "\\cfoot{{\\footnotesize{{Page \\thepage \\ of \\pageref{{finalpage}}}}}} \n",
    "\\rfoot{{}} \n",
    "\n",
    "\\renewcommand{\\headrulewidth}{0pt} %Do not print a rule below the header\n",
    "\\renewcommand{\\footrulewidth}{0pt}\n",
    "\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "% Title page\n",
    "\n",
    "\\begin{center}\n",
    "\\vspace{10cm}\n",
    "\\huge\\textbf{\\Titles}\n",
    "\\end{center}\n",
    "\\vspace{4cm}\n",
    "\n",
    "\\begin{center}\n",
    "\\Large\\textbf{\\today}\n",
    "\\end{center}\n",
    "\n",
    "\n",
    "\\begin{center}\n",
    "\\Large\\textbf{\\cityset}\n",
    "\\end{center}\n",
    "\n",
    "\\begin{center}\n",
    "\\large\\textbf{\\jobset}\n",
    "\\end{center}\n",
    "\\vspace{4cm}\n",
    "\n",
    "\\begin{center}\n",
    "\\textit{Authors: \\authors}\n",
    "\\end{center}\n",
    "\n",
    "\\begin{center}\n",
    "\\textit{Sources: \\sources}\n",
    "\\end{center}\n",
    "\\newpage\n",
    "\n",
    "% End title page'''\n",
    "    \n",
    "    for index, row in fetch_df.iterrows():\n",
    "        print(index)\n",
    "        #print(row['map_url'])\n",
    "        #map_file_name = str(index) + '.jpg'\n",
    "        #map_list.append(map_file_name)\n",
    "        #urllib.request.urlretrieve(str(row['map_url']), map_file_name)\n",
    "        tmp_content = r'''\n",
    "\n",
    "\\bigskip\n",
    "\n",
    "\\paragraph {%(jobtitle)s} Company\n",
    "\n",
    "\\noindent\\rule{8cm}{0.4pt}\n",
    "\\begin{description}\n",
    "\\item \\lbrack \\ \\textit{Map} ] %(map)s\n",
    "\\item \\lbrack \\ \\textit{Distance} ] %(distance)s\n",
    "\\item \\lbrack \\ \\textit{Drive Duration} ] %(duration)s\n",
    "\\item \\lbrack \\ \\textit{Keywords} ] %(keywords)s\n",
    "\\item \\lbrack \\ \\textit{Salary} ] %(salary)s\n",
    "\\item \\lbrack \\ \\textit{Full Text} ] %(fulltext)s\n",
    "\\item \\lbrack \\ \\textit{Link} ] \\url{%(link)s}\n",
    "\\end{description}\n",
    "\n",
    "\\begin{center}\n",
    "\\vspace{3cm}\n",
    "--------- \\textit{\\lastwords} ---------\n",
    "\\end{center}\n",
    "\n",
    "\\newpage\n",
    "\n",
    "'''\n",
    "        '''tmp_content = tmp_content.format(**)'''\n",
    "        tmp_content = tmp_content % { 'jobtitle' : row['title'], 'map' : row['map_url'] , 'distance' : row['distance'], 'duration' : 'other butts' , 'keywords' : 'butty' , 'salary' : 'moneybutts', \n",
    "                                            'fulltext' : row['body_text'], 'link' : row['post_link'] }\n",
    "        tmp_content = tmp_content.encode('ascii',errors='ignore').decode()\n",
    "        tmp_content = tmp_content.replace('&', '\\&').replace('$', '\\$').replace('#', '\\#').replace('|', '').replace('_', '\\_')\n",
    "        #tmp_content = codecs.encode(tmp_content, 'utf-8').decode('utf-8')\n",
    "        content = content + tmp_content\n",
    "        # ID \ttitle \tcompany \tlocation \tpost_link \tcomp_link \tezapply \tcompany_pic \tpulldate \tcomp_loc \trating \tsalaries_link \treviews_link \tl_company \tpostdate \tbody_text \tsummary \tbenefits\n",
    "        filename = 'job_scrap_output' + suffix + '.tex'\n",
    "\n",
    "    content = content + '''\\end{document}'''\n",
    "    with open(filename,'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    cmd = ['pdflatex', filename]\n",
    "    subprocess.check_output(cmd)\n",
    "\n",
    "    os.unlink('job_scrap_output.log')\n",
    "    os.unlink('job_scrap_output.aux')\n",
    "    #for file in map_list:\n",
    "        #os.unlink(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-ID-0\n",
      "L-ID-1\n",
      "L-ID-2\n",
      "L-ID-3\n",
      "L-ID-4\n",
      "L-ID-5\n",
      "L-ID-6\n",
      "L-ID-7\n",
      "L-ID-8\n",
      "L-ID-9\n",
      "L-ID-10\n",
      "L-ID-11\n",
      "L-ID-12\n",
      "L-ID-13\n",
      "L-ID-14\n",
      "L-ID-15\n",
      "L-ID-16\n",
      "L-ID-17\n",
      "L-ID-18\n",
      "L-ID-19\n",
      "L-ID-20\n",
      "L-ID-21\n",
      "L-ID-22\n",
      "L-ID-23\n",
      "L-ID-24\n",
      "i-ID-0\n",
      "i-ID-1\n",
      "i-ID-2\n",
      "i-ID-3\n",
      "i-ID-4\n",
      "i-ID-5\n",
      "i-ID-6\n",
      "i-ID-7\n",
      "i-ID-8\n",
      "i-ID-9\n",
      "i-ID-10\n",
      "i-ID-11\n",
      "i-ID-12\n",
      "i-ID-13\n",
      "i-ID-14\n",
      "i-ID-15\n",
      "i-ID-16\n",
      "i-ID-17\n",
      "i-ID-18\n",
      "i-ID-19\n",
      "i-ID-20\n",
      "i-ID-21\n",
      "i-ID-22\n",
      "i-ID-23\n",
      "i-ID-24\n"
     ]
    }
   ],
   "source": [
    "tex_output(fetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here's below\n",
    "\n",
    "'''indeed_pg_num = 0\n",
    "                site_ind = 0 # set to 0 at start of site and compared to results so there are 'results' number of pulls per site\n",
    "                list_o_divs = [] # holds divs if multiple pages\n",
    "                tmp_dict = {} # holds info on each div loop\n",
    "                # https://www.indeed.com/jobs?q=data+science&l=boston&sort=date\n",
    "                res_left = results\n",
    "                base = 'https://www.indeed.com/jobs?'\n",
    "                while res_left > 0:            \n",
    "                    params = {'q' : job_title,'l' : city, 'start' : (results-res_left),  'sort' : 'date', 'radius': '25'}\n",
    "                    page = requests.get(base, params) \n",
    "                    time.sleep(1)  \n",
    "                    soup = get_soup(page.text)\n",
    "                    divs = soup.find_all(name=\"div\", attrs={\"class\":\"row\"})\n",
    "                    list_o_divs.append(divs)\n",
    "                    res_left = res_left - len(divs)\n",
    "                    indeed_pg_num = indeed_pg_num + 1\n",
    "                print('total indeed pages : ' + str(indeed_pg_num))\n",
    "                for divs in list_o_divs:\n",
    "                    for div in divs:\n",
    "                        if (site_ind < results):\n",
    "                            tmp_dict['sID'] = 'ID' + str(num)\n",
    "                            tmp_dict['site'] = site\n",
    "                            tmp_dict['pulldate'] = str(time.strftime(\"%M%D%y\", time.localtime(time.time())))\n",
    "                            tmp_dict['link'] = 'http://www.indeed.com' + div.find(name='a', attrs={'class':'turnstileLink'})['href']\n",
    "                            #tmp_dict['link'] = extract_link(div, site)\n",
    "                            tmp_dict['title'] = div.find(name='a', attrs={'class':'turnstileLink'})['title']\n",
    "                            # tmp_dict['title'] = extract_job_title(div, site)\n",
    "                            tmp_dict['summary'] = div.find('span', attrs={'class': 'summary'}).text.strip()\n",
    "                            # tmp_dict['summary'] = extract_summary(div, site)\n",
    "                            #tmp_dict['salary'] = extract_salary(div, site)\n",
    "                            # tmp_dict['location'] = extract_location(div, site).strip() # two things\n",
    "                            if div.find('span', attrs={'class': 'location'}).text is None:\n",
    "                                tmp_dict['location'] = div.find('div', attrs={'class': 'location'}).text.strip()\n",
    "                            else:\n",
    "                                tmp_dict['location'] = div.find('span', attrs={'class': 'location'}).text.strip()\n",
    "                            tmp_dict['tags'] = extract_tags(div, site)\n",
    "                            #tmp_dict['id'] = extract_id(div, site)\n",
    "                            tmp_dict['id'] = div['id']\n",
    "                            if div.find('div', attrs={'class': 'iaP'}) is not None:\n",
    "                                tmp_dict['ezapply'] = True\n",
    "                            else:\n",
    "                                tmp_dict['ezapply'] = False\n",
    "                            # tmp_dict['ezapply'] = extract_easyapply(div, site)\n",
    "                            tmp_dict['postdate'] = extract_postdate(div, site)\n",
    "                            #tmp_dict['company'] = extract_company(div, site).strip()\n",
    "                            tmp_dict['company'] = div.find(name=\"span\", attrs={\"class\":\"company\"}).text.replace('\\n', '').strip()\n",
    "                            tmp_dict['comp_loc'] = str(extract_company(div, site).strip() + ', ' + extract_location(div, site).strip())\n",
    "                            tmp_df = pd.DataFrame(tmp_dict, index=[tmp_dict['sID']])\n",
    "                            job_df = job_df.append(tmp_df, sort=False)\n",
    "                            num = num + 1\n",
    "                            site_ind = site_ind + 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''                site_ind = 0 # set to 0 at start of site and compared to results so there are 'results' number of pulls per site\n",
    "                list_o_divs = [] # holds divs if multiple pages\n",
    "                tmp_dict = {} # holds info on each div loop\n",
    "                # https://stackoverflow.com/jobs?q=data+scientist&l=boston&d=20&u=Miles\n",
    "                pg = 1 # page counter \n",
    "                base = 'https://stackoverflow.com/jobs?'\n",
    "                tot_pg = ((results // 20) + 1)\n",
    "                print('Stack overflow total pages: ' + str(tot_pg))\n",
    "                while pg <= tot_pg: \n",
    "                    params = {'q' : job_title, 'sort' : 'p', 'l' : city, 'd' : '20', 'u': 'Miles', 'pg': pg} \n",
    "                    page = requests.get(base, params) \n",
    "                    print(page.url)\n",
    "                    time.sleep(1)\n",
    "                    soup = get_soup(page.text)\n",
    "                    divs = soup.find_all(name=\"div\", attrs={\"class\":\"-job-summary\"})\n",
    "                    list_o_divs.append(divs)\n",
    "                    pg = pg + 1\n",
    "                for divs in list_o_divs:\n",
    "                    for div in divs:\n",
    "                        if (site_ind < results): # if there is a div past the number of results for the site, doesn't add it to tmp_dict\n",
    "                            tmp_dict['sID'] = 'ID' + str(num)\n",
    "                            tmp_dict['site'] = site\n",
    "                            tmp_dict['pulldate'] = str(time.strftime(\"%m-%d-%Y_%I-%M_%p\", time.localtime(time.time())))\n",
    "                            tmp_dict['link'] = 'https://www.stackoverflow.com' + div.find(name='a', attrs={'class':'s-link'})['href']\n",
    "                            # tmp_dict['link'] = extract_link(div, site)\n",
    "                            tmp_dict['title'] = div.find(name='a', attrs={'class':'s-link'})['title']\n",
    "                            # tmp_dict['title'] = extract_job_title(div, site)\n",
    "                            tmp_dict['summary'] = 'No Stack Summary yet'\n",
    "                            if div.find('div', attrs={'class': '-perks'}).text is None:\n",
    "                                tmp_dict['salary'] = 'NA'\n",
    "                            else:\n",
    "                                div.find('div', attrs={'class': '-perks'}).text.replace('\\n', ' ').replace('\\r', '').strip()\n",
    "                            # tmp_dict['salary'] = extract_salary(div, site)\n",
    "                            tmp_dict['location'] = div.find_all('div', attrs={'class': '-company'}).split('-')[1].text\n",
    "                            # tmp_dict['location'] = extract_location(div, site).strip()\n",
    "                            tmp_dict['tags'] = ', '.join(div.find_all('a', attrs={'class': 'post-tag job-link no-tag-menu'}))\n",
    "                            # tmp_dict['tags'] = extract_tags(div, site)\n",
    "                            tmp_dict['id'] = div.find('span', attrs={'class': 'fav-toggle'})['data-jobid']\n",
    "                            #tmp_dict['id'] = extract_id(div, site)\n",
    "                            tmp_dict['ezapply'] = 'No Easy Applications on Stack'\n",
    "                            if div.find('span', attrs={'class': 'ps-absolute pt2 r0 fc-black-500 fs-body1 pr12 t24'}).text is None:\n",
    "                                tmp_dict['postdate'] = div.find('span', attrs={'class': 'ps-absolute pt2 r0 fc-black-500 fs-body1 pr12 t32'}).text\n",
    "                            else:\n",
    "                                tmp_dict['postdate'] = div.find('span', attrs={'class': 'ps-absolute pt2 r0 fc-black-500 fs-body1 pr12 t24'}).text\n",
    "                            # tmp_dict['postdate'] = extract_postdate(div, site)\n",
    "                            tmp_dict['company'] = div.find_all(name=\"div\", attrs={\"class\":\"-company\"}).split('-')[0].text.replace('\\n', '').replace('\\r','')\n",
    "                            #tmp_dict['company'] = extract_company(div, site).split('-')[0].strip()\n",
    "                            tmp_dict['comp_loc'] = div.find_all('div', attrs={'class': '-company'}).text\n",
    "                            tmp_df = pd.DataFrame(tmp_dict, index=[tmp_dict['sID']])\n",
    "                            job_df = job_df.append(tmp_df, sort=False)\n",
    "                            num = num + 1\n",
    "                            site_ind = site_ind + 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
